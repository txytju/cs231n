{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Neural Nets\n",
    "In the previous homework you implemented a fully-connected two-layer neural network on CIFAR-10. The implementation was simple but not very modular since the loss and gradient were computed in a single monolithic function. This is manageable for a simple two-layer network, but would become impractical as we move to bigger models. Ideally we want to build networks using a more modular design so that we can implement different layer types in isolation and then snap them together into models with different architectures.\n",
    "\n",
    "In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a `forward` and a `backward` function. The `forward` function will receive inputs, weights, and other parameters and will return both an output and a `cache` object storing data needed for the backward pass, like this:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "The backward pass will receive upstream derivatives and the `cache` object, and will return gradients with respect to the inputs and weights, like this:\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive derivative of loss with respect to outputs and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "After implementing a bunch of layers this way, we will be able to easily combine them to build classifiers with different architectures.\n",
    "\n",
    "In addition to implementing fully-connected networks of arbitrary depth, we will also explore different update rules for optimization, and introduce Dropout as a regularizer and Batch Normalization as a tool to more efficiently optimize deep networks.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from the cs231n directory and try again:\n",
      "python setup.py build_ext --inplace\n",
      "You may also need to restart your iPython kernel\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('y_val: ', (1000,))\n",
      "('X_test: ', (1000, 3, 32, 32))\n",
      "('X_train: ', (49000, 3, 32, 32))\n",
      "('X_val: ', (1000, 3, 32, 32))\n",
      "('y_test: ', (1000,))\n",
      "('y_train: ', (49000,))\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "  print(('%s: ' % k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: foward\n",
    "Open the file `cs231n/layers.py` and implement the `affine_forward` function.\n",
    "\n",
    "Once you are done you can test your implementaion by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.7698488884e-10\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_forward function\n",
    "\n",
    "# 2张图片，图片的 shape 是 (4,5,6)\n",
    "# 120 -> 3 的全连接神经网络\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "# 造测试数据\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print('Testing affine_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: backward\n",
    "Now implement the `affine_backward` function and test your implementation using numeric gradient checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  1.09081995087e-10\n",
      "dw error:  2.17526355046e-10\n",
      "db error:  7.73697883449e-12\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_backward function\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "    \n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-10\n",
    "print('Testing affine_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: forward\n",
    "Implement the forward pass for the ReLU activation function in the `relu_forward` function and test your implementation using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.99999979802e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 5e-8\n",
    "print('Testing relu_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: backward\n",
    "Now implement the backward pass for the ReLU activation function in the `relu_backward` function and test your implementation using numeric gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  0.333333333333\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be around 3e-12\n",
    "print('Testing relu_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sandwich\" layers\n",
    "There are some common patterns of layers that are frequently used in neural nets. For example, affine layers are frequently followed by a ReLU nonlinearity. To make these common patterns easy, we define several convenience layers in the file `cs231n/layer_utils.py`.\n",
    "\n",
    "For now take a look at the `affine_relu_forward` and `affine_relu_backward` functions, and run the following to numerically gradient check the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward:\n",
      "dx error:  1.0\n",
      "dw error:  1.0\n",
      "db error:  1.0\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "print('Testing affine_relu_forward:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss layers: Softmax and SVM\n",
    "You implemented these loss functions in the last assignment, so we'll give them to you for free here. You should still make sure you understand how they work by looking at the implementations in `cs231n/layers.py`.\n",
    "\n",
    "You can make sure that the implementations are correct by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svm_loss:\n",
      "loss:  8.9996027491\n",
      "dx error:  1.40215660067e-09\n",
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.3025458445\n",
      "dx error:  9.38467316199e-09\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n",
    "\n",
    "# Test svm_loss function. Loss should be around 9 and dx error should be 1e-9\n",
    "print('Testing svm_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = softmax_loss(x, y)\n",
    "\n",
    "# Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8\n",
    "print('\\nTesting softmax_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer network\n",
    "In the previous assignment you implemented a two-layer neural network in a single monolithic class. Now that you have implemented modular versions of the necessary layers, you will reimplement the two layer network using these modular implementations.\n",
    "\n",
    "Open the file `cs231n/classifiers/fc_net.py` and complete the implementation of the `TwoLayerNet` class. This class will serve as a model for the other networks you will implement in this assignment, so read through it to make sure you understand the API. You can run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Testing test-time forward pass ... \n",
      "[[ 11.53165108  12.2917344   13.05181771  13.81190102  14.57198434\n",
      "   15.33206765  16.09215096]\n",
      " [ 12.05769098  12.74614105  13.43459113  14.1230412   14.81149128\n",
      "   15.49994135  16.18839143]\n",
      " [ 12.58373087  13.20054771  13.81736455  14.43418138  15.05099822\n",
      "   15.66781506  16.2846319 ]]\n",
      "Testing training loss (no regularization)\n",
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.83e-08\n",
      "W2 relative error: 3.37e-10\n",
      "b1 relative error: 8.01e-09\n",
      "b2 relative error: 4.33e-10\n",
      "Running numeric gradient check with reg =  0.7\n",
      "W1 relative error: 3.12e-07\n",
      "W2 relative error: 2.85e-08\n",
      "b1 relative error: 1.56e-08\n",
      "b2 relative error: 7.76e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-3\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ... ')\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "print('Testing test-time forward pass ... ')\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "print(scores)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "print('Testing training loss (no regularization)')\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "\n",
    "for reg in [0.0, 0.7]:\n",
    "  print('Running numeric gradient check with reg = ', reg)\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver\n",
    "In the previous assignment, the logic for training models was coupled to the models themselves. Following a more modular design, for this assignment we have split the logic for training models into a separate class.\n",
    "\n",
    "Open the file `cs231n/solver.py` and read through it to familiarize yourself with the API. After doing so, use a `Solver` instance to train a `TwoLayerNet` that achieves at least `50%` accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 2450) loss: 2.307505\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c65b493fbb0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 print_every=100)\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m##############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#                             END OF YOUR CODE                               #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/txy/assignment2/cs231n/solver.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_it\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlast_it\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mepoch_end\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                 train_acc = self.check_accuracy(self.X_train, self.y_train,\n\u001b[1;32m--> 291\u001b[1;33m                     num_samples=self.num_train_samples)\n\u001b[0m\u001b[0;32m    292\u001b[0m                 val_acc = self.check_accuracy(self.X_val, self.y_val,\n\u001b[0;32m    293\u001b[0m                     num_samples=self.num_val_samples)\n",
      "\u001b[1;32m/home/txy/assignment2/cs231n/solver.py\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[1;34m(self, X, y, num_samples, batch_size)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# This is equivalent to concatenation along the second axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/txy/assignment2/cs231n/classifiers/fc_net.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# using sandwich layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mar1_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mar1_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_relu_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0ma2_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma2_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/txy/assignment2/cs231n/layer_utils.py\u001b[0m in \u001b[0;36maffine_relu_forward\u001b[1;34m(x, w, b)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;33m-\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mObject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgive\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbackward\u001b[0m \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelu_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelu_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfc_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelu_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/txy/assignment2/cs231n/layers.py\u001b[0m in \u001b[0;36maffine_forward\u001b[1;34m(x, w, b)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m###########################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;31m# broadcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m###########################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet()\n",
    "solver = None\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "solver = Solver(model, data, \n",
    "                update_rule=\"sgd_momentum\", \n",
    "                optim_config={'learning_rate':6e-4}, \n",
    "                lr_decay=0.8,\n",
    "                batch_size=200,\n",
    "                print_every=100)\n",
    "solver.train()\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHVCAYAAAAzabX0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXe8HFX5/z/nltz0BEgIISSEGnoooRchIILhSxVBiooo\noqjo158IoqL0/lWkC4hKEZUmHUxCSSGQhBRSCWmk3vTc5ObWnd8fu7M7O3Nm5pzZM7uzu5+3L8ze\n3TNnzsycOfOZ53nOc4RlWSCEEEIIIYVTU+oGEEIIIYRUChRWhBBCCCGGoLAihBBCCDEEhRUhhBBC\niCEorAghhBBCDEFhRQghhBBiCAorQgghhBBDUFgRQgghhBiCwooQQgghxBB1pdpxv379rKFDh5Zq\n94QQQgghykyZMmWtZVn9w8qVTFgNHToUkydPLtXuCSGEEEKUEUIsUSlHVyAhhBBCiCEorAghhBBC\nDEFhRQghhBBiCAorQgghhBBDUFgRQgghhBiCwooQQgghxBAUVoQQQgghhqCwIoQQQggxBIUVIYQQ\nQoghKKwIIYQQQgxBYUUIIYQQYggKK0IIIYQQQ1BYEUIIIYQYgsKKEEIIIcQQFFaEEEIIIYagsCKE\nEEIIMUTFCqtUysKmbe1o7egsdVMIIYQQUiVUrLCatWIzhv/+bXwwf22pm0IIIYSQKqFihVXvbnUA\ngM0t7SVuCSGEEEKqhcoVVl3rAQCbt1FYEUIIIaQ4VKyw6tU1bbHatK2jxC0hhBBCSLVQscKqrrYG\n/Xo24IsNzaVuCiGEEEKqhIoVVgBw6JC+GPcZg9cJIYQQUhwqWljtNaAn1m5phWVZpW4KIYQQQqqA\nihZWPRvq0ZGy0NqRKnVTCCGEEFIFVLiwqgUANLUwgJ0QQggh8VPRwmr7Hg0AgFkrNpW4JYQQQgip\nBipaWB0wqDcAYE1Ta4lbQgghhJBqoKKFVbcuaVcgY6wIIYQQUgwqWlh1raewIoQQQkjxqGhh1VCX\nPryW9s4St4QQQggh1UBFC6sutTUQghYrQgghhBSHihZWQgg01NWglRYrQgghhBSBihZWALDr9j0w\ne+XmUjeDEEIIIVVAxQurPQf0xPIN20rdDEIIIYRUARUvrPr3bMCaLcxjRQghhJD4qXhh1btrHba0\ndnAhZkIIIYTETsULq25d6mBZwDYGsBNCCCEkZipeWK3LuAHveGNuiVtCCCGEkEqn4oXVltYOAMDL\n01eUuCWEEEIIqXQqXljZbM0ILEIIIYSQuKh4YfXzU4cBAE7Yq3+JW0IIIYSQSqfihVX/Xg04eHBf\ntHVyWRtCCCGExEvFCysA6NW1Dptb6AokhBBCSLxUhbDq0aUOLW1Mt0AIIYSQeKkKYdWtSy3zWBFC\nCCEkdqpCWHWtp7AihBBCSPxUibCqoSuQEEIIIbFTFcKqW30tWjoorAghhBASL1UhrLbv0QXtnRbu\nH/NZqZtCCCGEkAqmKoTVHv17AgDufns+Nja3lbg1hBBCCKlUqkJY1dfmDjNllbAhhBBCCKloqkJY\n1dWKUjeBEEIIIVVAVQireoewosQihBBCSFxUhbCqq6mKwySEEEJIiakKxeF0BTLEihBCCCFxURXC\nKj94ndKKEEIIIfFAYUUIIYQQYoiqEFZ1NQ5XIHUVIYQQQmKiKoQVLVaEEEIIKQahwkoIMVgIMVYI\nMVsIMUsIcbWkzMVCiBlCiJlCiAlCiOHxNDcaecHr1FWEEEIIiYk6hTIdAH5uWdZUIUQvAFOEEO9Y\nljXbUWYRgC9ZlrVBCHE6gEcBHBlDeyPRsyF3mLRYEUIIISQuQoWVZVkrAazMfG4SQswBMAjAbEeZ\nCY5NPgSwi+F2FkTX+trsZ+oqQgghhMSFVoyVEGIogEMATAoodjmAN3y2v0IIMVkIMXnNmjU6uzYG\nLVaEEEIIiQtlYSWE6AngeQA/tSxrs0+Zk5AWVr+U/W5Z1qOWZY2wLGtE//79o7S3YLgIMyGEEELi\nQiXGCkKIeqRF1dOWZb3gU+YgAI8BON2yrHXmmmgWixYrQgghhMSEyqxAAeBxAHMsy7rXp8wQAC8A\nuNSyrPlmm2iWkfe8hwWNTaVuBiGEEEIqEBVX4LEALgUwUggxLfPfV4UQVwohrsyU+S2AHQA8mPl9\nclwNNsFTHy4tdRMIIYQQUoGozAocB0CElPkugO+aalTc1IjAwyGEEEIIiURVZF53U0NdRQghhJAY\nqE5hRWVFCCGEkBioGmF189kHZD/TE0gIIYSQOKgaYbVT767ZzyI4ZIwQQgghJBJVI6xqHEdKTyAh\nhBBC4qBqhJVw+P/oCiSEEEJIHFSPsHJ8ZroFQgghhMRB1Qgrp5iirCKEEEJIHFSnsKLFihBCCCEx\nUEXCKveZuooQQgghcVA1wqp3t/rsZ8ZYEUIIISQOqkZY7b9z7+znNz9dVcKWEEIIIaRSqRph5Yyr\nmr1ycwlbQgghhJBKpWqEFSGEEEJI3FBYEUIIIYQYgsKKEEIIIcQQFFaEEEIIIYagsCKEEEIIMURV\nCash23cvdRMIIYQQUsFUlbD60zcOKXUTCCGEEFLBVJWw6tu9PrwQIYQQQkhEqkpYCXApG0IIIYTE\nR3UJK+oqQgghhMRIVQkrQgghhJA4obAihBBCCDFEVQkrpytwQeOW0jWEEEIIIRVJlQmrnLI68/5x\nJWwJIYQQQiqR6hJWjs/NbZ0lawchhBBCKpPqElYOZdWltqoOnRBCCCFFoKrUhTOPVVtnCqs2tZSw\nNYQQQgipNKpLWLnyWM1Zubk0DSGEEEJIRVJdwsr1d00NM4YSQgghxBxVJazcymreKlqsCCGEEGKO\nqhJW7rUCb319bolaQgghhJBKpLqEFT1/hBBCCImR6hJWpW4AIYQQQiqaqhJWMizLKnUTCCGEEFIh\nVJWwEhJfYIq6ihBCCCGGqC5hJfmuk8qKEEIIIYaoLmElUVYpugIJIYQQYojqElYSmxWFFSGEEEJM\nUVXCSuYLpCeQEEIIIaaoKmFFVyAhhBBC4qS6hJXkuxRNVoQQQggxRHUJK6ZbIIQQQkiMVJewknxH\nVyAhhBBCTFFdwkoWY0WTFSGEEEIMUV3CSppuoQQNIYQQQkhFUlXCSgZdgYQQQggxRVUJK5krkEva\nEEIIIcQUVSWsZNBgRQghhBBTVJWwklqsqKwIIYQQYojqElZcK5AQQgghMVJdwkpisbIorAghhBBi\niKoSVjLOvH88Vm9uQXtnqtRNIYQQQkiZU1XCSpZ5vbmtE0feOhrXvziz6O0hhBBCSGVRVcKqrrYG\nT11+pPS3d2avLnJrCCGEEFJpVJWwAoDj9upX6iYQQgghpEKpOmHlR40ssp0QQgghRAMKK0IIIYQQ\nQ1BYZWhp7yx1EwghhBBS5lBYZejgmoGEEEIIKZCqFFYXjBjs+Y55QgkhhBBSKFUprM4fsYvnOwtU\nVoQQQggpjKoUVjIJ1UlXICGEEEIKpCqFVUoioqirCCGEEFIoVSmsqKEIIYQQEgfVKayorAghhBAS\nA1UqrKisCCGEEGKe6hRWpW4AIYQQQiqSqhRWKVqsCCGEEBIDVSms/Hjsg4X4dPmmUjeDEEIIIWVK\nXakbUAr8DFY3vzYHALD49lFFbA0hhBBCKoWqtFjRFUgIIYSQOKhKYUVZRQghhJA4qEphRWVFCCGE\nkDioSmG13869S90EQgghhFQgVSmsBvTuiud/cEypm0EIIYSQCqMqhRUA7LNTr7y/ezZU5QRJQggh\nhBikaoVVj4Y6HLPHDtm/T91vQAlbQwghhJBKIFRYCSEGCyHGCiFmCyFmCSGulpQRQoj7hBALhBAz\nhBCHxtNcszizLnSkGNFOCCGEkMJQ8X91APi5ZVlThRC9AEwRQrxjWdZsR5nTAeyV+e9IAA9l/k00\nznxWW1s7StgSQgghhFQCoRYry7JWWpY1NfO5CcAcAINcxc4C8DcrzYcA+gohBhpvrWGcFqvRcxtL\n1xBCCCGEVARaMVZCiKEADgEwyfXTIABfOP5eBq/4ghDiCiHEZCHE5DVr1ui1NAaYgZ0QQgghJlEW\nVkKIngCeB/BTy7I2R9mZZVmPWpY1wrKsEf37949ShVEoqwghhBBiEiVhJYSoR1pUPW1Z1guSIssB\nDHb8vUvmu0RDixUhhBBCTKIyK1AAeBzAHMuy7vUp9h8A38zMDjwKwCbLslYabGcsUFcRQgghxCQq\nswKPBXApgJlCiGmZ734FYAgAWJb1MIDXAXwVwAIAzQAuM99U81hUVoQQQggxSKiwsixrHAARUsYC\ncJWpRhULP1llWRbShjpCCCGEEHWqNvM64B9jxVyhhBBCCIlCdQurlM/3dBESQgghJAJVLaz85FMU\nYdXU0o7GppbCGkQIIYSQsqa6hZWfK9DHkhXESXe/hyNuGV1giwghhBBSzlS5sJJ/v25rK1KagVZr\nt7QaaBEhhBBCypmqFla2y+/wodvlfX/cHWNx/9gFpWgSIYQQQsoYCisAg7fr7vnt3nfmV0yeq47O\nVMUcCyGEEJJkqlpY2VrDL2dVc1tnEVsTD41NLdjz+jfw9w+XlLophBBCSMVT3cIq82+NTy7Qzgqw\n8nyxfhsA4IWpiV+6kRBCCCl7qlpY2a7AGh+LVUdn+Qsr+9DK/0gIIYSQ5FPVwirnCpT/3tEZIe9C\nwuDCPIQQQkjxqGphZVusduzVIP399jfn4pwHxwMAFq7Zgk3N7QCAjxatx+wVm4vTSFNUgFuTEEII\nSTpVLaxsrXHG8J1x/0WHeH5/YepyfLJ0Izo6Uxh5z3s44/4PAABff2QivnrfB8VsamTswHzKKkII\nISR+qlpYOWOszjhoZ99yD7/3OYBcIHg5QVcgIYQQUjyqWljZFiu/WYE2d789P/7GxAw9gYQQQkj8\nVLWwsi1WtWHKqozJzQqksiKEEELipqqFVS6PVQULKzoDCSGEkKJR3cLKjrGqYIuVDV2BhBBCSPxU\ntbBKKcZYOelMlZdCyboCy6vZhBBCSFlS5cIqE2Ol4QrsSJVn0lDqKkIIISR+qlpYhS3CHLQNqT7a\nOlIY/vu38cr0FaVuCiGEkIRS1cIqyqzAVJkpq5wrsLzanUTWb23Dpm3tuPm12aVuCiGEkIRS1cIK\nEWKswkKsXpi6DK0dndHbZBjOCiSEEEKKR1ULq1SEWYFhFqv//ed0/OG/nxXULpNUcCYJQgghJHFU\ntbCKksfKUohdb9zcGq1BMUJPICGEEBI/VS2soswKdFqsLMvCorVbtffb3NaBtg6vQmtu68Cm5nbt\n+oJg5nVz8BwSQggJo8qFVfpfHXeZU1g9Pm4RTrr7Xcxctklrv/v99i2c8+B4z/cn3/Meht/4tlZd\nYTDGihBCCCkeVS2s7JlyesIq93nq0g0AgE9X5AsrFcvGrBWbPd+t3NSi3hBN6AokhBBC4qeqhdVJ\nw3YEoOcKdKYtsK1BW1s7zDbMIDlXIDEFrYCEEEL8qCt1A0rJfd84BGuaWlFXq64vO52mH7/lYqx0\nzqOOVAo79upaeEMLgBLAPIy1IoQQ4kdVC6uu9bUYvH13rW3emb3a853sQXvoTe8AABbfPipa4wzD\nBKGEEEJI/FS1KzAKv315VvazbQ1ya5YkSRi6As1DVyAhhBA/KKwKwG+NQcuVkuGNmSvRGZayPTYo\nAgghhJBiQWFlgCDJ9PSkpfjB01Px5w8WFq09UmiyIoQQQmKHwqoAJi9eD8C7zI3zr1+/9CkAYFWM\nqRSCoCvQHAxTI4QQEgaFVQHEmXfKFHQEEkIIIcWDwsoA5WDJ4KxAQgghJH4orAwwdcmGUjchFMoq\nc+hk6ieEEFJdUFgZYPTcxry/k2QcSlBTKoYkXV9CCCHJgsIqIWyJuCzOF+ubDbeEEEIIIVGhsHIw\nfHBfI/VEMWg8MHaB9jYffLYGx985Fje+Mju8TbSyGIOuQEIIIX5QWDl4+apj0UVj3UCTtHWksp+H\nXvuaVGhta+vEZX/5CEvWbQUAzF3ZBAB4Yvwi33opqAghhJDiQWHlwsQCu7IZeLpWjrvemuf57t15\njRg7bw1ue32ufpsYbUUIIYTEDoWVCxMrz7w6Y2XhlUjIJfvUbyQtV4XDU0gIISQMCisX7izqySKt\nrPSamOTjIYQQQioLCisXcemqv4xfbKwuK/tvrrHtnSls2tbuv02E42rrSOGW12YH1ltNMGadEGKK\ndVtaS90EEhMUVglFFpOVdQVKRNJVT0/F8N+/bbQNL01bjj9/sAh3vZUf0/Xp8k1Vmcm9+o6YEBIH\nny7fhMNu/i/+PWVZqZtCYoDCKiGo6JQgi8nbs1dHrtePzkzAWUdnrpJ3Zq/GGX8axwGBEEIiMmfl\nZgDAhM/XlrglJA4orBJKsNspSvC6d5ttbZ0Yeu1reN5HJNmbOK1nC9dsAQDMX92k3YZi8pfxi/Di\nJxR/hJDkYY/GggEGFQmFVRkhCshMKZNijU0tAIA/jJ7vs03u9s+1IfNbwv1iv39lNn723PRY6uZQ\nSAgxAZMNVyYUVkXEVFySTjVBRd1vSw+MXYBpX2wMrM/eJuG6ihBCkgsH0IqGwspFQ118p6RTI0mW\nzDplfxPlnnSKsetfnInf/WeW57e73pqHsx8YL90m164IOyeEEJLF9gZwOK1MKKxcvPaT4/CdY3eL\npe7NLeoLLctuuEJEjTM1w9OTluLJCYuV65OVS7orMA6qcSYkISQ++KJamVBYudhzx1645KghsdR9\n6eOTfH/TyaYe5QEftIlOdbYljUvkEEIIIV4orCQUEiQexKwVmzXaoPZdGIUYWYI2rUbjTVz9ghBS\nXVTj+FlNUFgllKBpuNnM64aC2MPbIv9cbdAVSAgxCdMtVCYUVhKS0tVTKQuTFq7L/m3fhO/OW4PX\nZ+ot9BwUiK4jGIK2eX/+GkxdukGrXYQQUm3wFa2yobCSUGyPz4LGLXj2o6WuRgCPj1uECx79EO/O\na/Rs88OnpyrVHRQLlYuX8tvY+0vQqfnmEx/h3AcnKLXLzVf/+AHufmtepG0JIaSckCVfJpUDhZWE\nYppnV27ahlPufQ8t7SnPbwsat2TKtNgNC8Xf+qQnkvLKCefnnBj7+8TF+HT5JsVagpm9cjPuH7vA\nSF2EEFIOUFhVJhRWEpyd/dZzDox1X0ffNkbeBslnlXvQT1fJvr/4sUmB20jb5ci8/puXZ+GMP41T\n37hMWdC4BZu2tZe6GYSQCoGzqisbCqsABvbpiouOjCf1Qly4b9cg0bRo7VatuvJ/q56B4ZR738P5\nD+dcnJwdSAgphNy4zLGkEqGwkpC056bdHtNrBeZ+CxZJTtdoNvt79egqAMD81Vuynzk7kBBiAr8h\n/Y2ZK/HSJ8uL2xhiDAqrAOw+/9DFh+Lbxww1Uuc/P/5Cbd8RNdRzPvWHiQFlsRAW8B4Tyzduw51v\nzi2pqKGeIoSYIGwo+cHTU/HT56YVpS3EPBRWAdgWotMPHIihO3Q3Uuc1z8/Ifn5m0lLfcgLCY0lS\n0Vq/enFm3t8qYkAnLqtUxryfPPsJHnz3c60kq3FBVyCpZFZvbkFHp3cyDTGIxbUCKxkKK0XieJi6\nRVB4G6LvK0xfBQmwJKwV2NaRHuhTJTQbNWms9UhIObJuSyuOvHU0bn9jbqmbUhXwHa0yobBSxHkD\nHDy4b1H354eOxAhcK1Cjrly7ytMvtmxDM4Ze+xren79Ge9sz76/8GZCkutnQ3AYAGCvJnUfMUZ6j\nJ1GFwkpCkAvskCF98fwPjom9DULSjij5tVRn78lil+zvVm9uyX6221Cu8UZTlqQzw/9ryjLtbTtS\nxTvos+4fh1H3fVC0/ZHyp6MzhYsf+xAfLVpf6qaQELIJQukMrEgorDSpr6lBbU1xbwb75puxfGPk\nOoKCvi0r+A3qrVmr8beJS9Jt8Tl0zpQzy/RlmxIRT0bKh5WbWjB+wTr87z8LD3rm3Vwc6AqsTCis\nVCnyHSCE8Axud76Zv+SLTotC5gSGWqAmfr4ub5/u8p1FtOYQOZ0pCz//53TMWUlBRqLCJz0hhUJh\npUgShxsVKVPQrEDJd9nM665fkyqrbnxlNho3t5S6GUVh8bqteH7qMlyluI4k8eftWatw8I1vo6W9\ns9RNUYZG4/KBFv7KhsJKkZKabE3sO+Q+Dk0S6mqDe1xI6jjxxPhF2rMvCbn19TnY2NyeW6ezjDAy\nViX0fq4U7NObxBd2UjgUVhJkK48XO8hwS2sH/u0IsC70DSc483q4MMpmf7eD1z11FGckjnIaonop\nN21rx8vTzGU/XtC4BXNX0U1XDiRFV1zxt8l4+L3PlcpW0zJTuixZtxX3vD0vcZaiJOXEm7JkPYZe\n+xqWb9wWWO6ut+bi8Fv+W6RWlScUVgHkCasS9n+B6OKgEKRjkJD/1tIWb0LBQs5/1LkGP//ndFz9\nD3PZj0+59z2c9gfO9CsnSv3Ye3v2au2cUpxp5uXyv07Gn8YswNL1zaVuCoBkWvifziSstuNp/Xhg\n7OdY09RajCaVLRRWipR6qCrYYmVZeGLcInzhM7CEWqwyZ8DvPFzz/PQCWmeODVvb8M7s1Xnf1URU\nZas2B7+5FYplWQz6J8Yw8bBOkAHFKHaC4aSQ5Ls+CVa9lvbORLQjKhRWZUKhXWxrWydufHU2Lnl8\nkrduy1J2I4jsWoH55ad9ET0VhEm+89eP8b2/Tc77rtjpMdys2LgNQ699zfP9D5+eij1+9XoJWkTK\nmTVNrWhu818FoFLFUSWSpGsVl6Vz6LWv4dbX5yiXX7ahGfv85k0885H/km9Jh8JKkewNIOl7Fx85\nJNZ9z1/dhL2uf8PzvZ+gH79gbVbtu8v4LcsiqyvAE+j5MSkvF4vXbvV8J7NYFXM8+3ixPGHjG5+u\nKmIrzPK3iYvxbBkPfGEkpT/LOPyW/+LM+8fHuo8EH35FUM7WmCg8+v5C5bKLMmP4GzPLd3yksJJQ\nW5t+7Pbt1iX7XZCar4vZIvLBZ2u1yl/82CS8MFU96Np9i8usK+7DV0v1YOG6F2Zi5rJNym0plKAU\nESTNL/89A2Pmrg4vGMBvX56F614wN9ty/dY2rNwUr+tVB9sim9S+s6BxS6mbUFYkNbCf8XD+JPWa\nqUBhJWFQ32743f/shz9/c0TuS5H3Tx61NfGexvpaef1Bg/4XG+SxVLJNwjKvO7fL5rFyvXHJtl+3\ntQ3PfrQU3/rLRyG169HS3oknxi2SxifJXgSjxlglkQ1b2zC9QLfrc5O/wHeenBxesIgcetM7OPq2\nMaVuRllTvo+h6iWJQ1Op+1EliE0KKx++fexu2KlP1+zffpf6kqOGoK423o4gq7+Lj9iysTWHiuq3\nLCtwrUAnuQSh7rL+9eucHb/geif3jf4MN746WzkVQqljrExy/iMTcdYD8bqBSHlTSG/PraxQ6sdr\nZZPE05sUkVfOliobCitF/PKN3Hz2gRjUt1us+66XWMTqa0Xwzal554ZarIQ9K9B7HpZtaMbaLWam\n374+c2Xg7xbS+aUAYGurN14sSAxWAiouoM0t7aHnkahRTm/PFEPhJOV6Zl3NJW5HkknKtYpCqLAS\nQjwhhGgUQnzq83sfIcQrQojpQohZQojLzDez9LgvcY0A+vdqAABcetSuse67vs7bwcLcWzqz+GUJ\nQsMGaWf9//joC3m9ripWbWrB2LmNgfX6HZb9dUdnKptvRbpPyXdJdAXG+RBcu6UNP3x6Kpas8wby\nVzNtHSnc9OrsrDCvVJKUdJIEk8hLFdPQNGlhcH6sSkLFYvUkgNMCfr8KwGzLsoYDOBHAPUKILgHl\nyxL3DTD3ptMx4dqRAICamF1NdRKLVVNrR2AW75TPrEBfJLP8ZNva5yGlIQzsbc5+YDwue/Lj4LIh\nbylTlmwI3pk0xip4E9226AyGv/vPLDwxfrHn+2IYF1rak5W7R4cHxi7AsF97Z8IWwkvTluPxcYtw\n55vhCTeTavwJy4pdKBRlxSGJ/SvuK3/Box9iwud6E7HKlVBhZVnW+wDk88UzRQD0Euk7smemrH+S\nlTKlI2Oi6ZexUnWpq/ENKjeN335mBMy208o7qZBqwXPTRRgYVikshhw2rkcZ90sZY/XkhMWhweb/\n/PgLNLVUthVFl7vemodWR1LHra0d2NZW2ILIHZ3pTquTlDVpOuPMP40rdROIQapNyDZuVg8ZKedY\nKxPK4H4A+wJYAWAmgKsty5K+KgshrhBCTBZCTF6zZo2BXRePjc1tAICdencNKWmeep/g+KA0D7qd\n0l3enTQ0u1agJEGo375KcWPI95i8wcvZzmuen4HrX5R62kmG/W94C8feoTZr8KF3P8/mwpFRzs+y\ndVvbirKf8n2kkUKJc9xWuffKObbKxoSw+gqAaQB2BnAwgPuFEL1lBS3LetSyrBGWZY3o37+/gV0X\nj86MVIx7BqAMv85YF2Axs03NHsuTpC5pjBWAW1/PuUxenrYivX3m75RDOoebtc2dM+dN595tZ8pC\ne6dX00eNZ4pzgHG3qbEp3JqnvY8KezyuVxAVm1vaccebc3HhoxOL0KJkUVlXu7JJ4rUKEz2plIUr\n/z6lOI0pc0wIq8sAvGClWQBgEYB9DNSbKOyYoiQFQs9ZGRBjpbkGnWr6hFy6BafFSg/LsnyTQYaZ\nxoN+Pvmed/PcR+VEqZYMvPGV2Ti7gtI32P22uUC3oV3P8XeODbzPkkhyRqjkkLSYJrs95XSttrR1\n4M1ZZrOh/+iZqcppc8oJE8JqKYCTAUAIMQDAMADq+evLBFuolCJcJ8qgoBViJcljFWbtUGqTT5l3\n563B0beN8SyWDBQ20Cxe57/A9O7XvYbLn/xY61wWapL2W8oGkAlZ8yO/SpVPjF+UmHUe4yaqBe/P\nH+gPZwsam3D/mM8i7S8qRhZh1iwf9yLiX6xvllqhK4YyUlZRmho2rr06YyWu/se0aA1KMCrpFp4F\nMBHAMCHEMiHE5UKIK4UQV2aK3ATgGCHETACjAfzSsqyKC/23x4/aElisdGbghW2zodkbJG1BL+Fn\nun71trhPmf0gn7HM+0CP4/RasJCygNGOVA/O/XSmLDQqBNbr8oOn/M3m3vQWenWrCLFCHrTNbR34\nxb+mY5N88xdHAAAgAElEQVSkvzg576EJ2OwTeH//mM+K/jaava6Bxx7/PXzRnyfh7rfnlya1Q8Dh\nXfLYJN8cZ1OXbshO0lHh7VmrsMevXse8VU26LVRi7ZZWHH/nWNz4yuxY6i8lcbjpLcvCHW/Oxedr\nClvuKCnWvaS0IwoqswK/YVnWQMuy6i3L2sWyrMcty3rYsqyHM7+vsCzrVMuyDrQs6wDLsp6Kv9nF\np9Oy1w4rhbDS3yYbY+XqnX7LwKh2Ylm9ftv6VRnJOlPAeQ/b3T1vz8MRt45WFleqD8ug6+YeWHXF\ns0rxQgbvZyYtxb+mLMOfQqwuU5ZswOg58nUH7357ftHfRv101VMfLsFqx4ykMXNXBwa4F4p97Vvb\nC3NJ6hF+vcctWIsfPj0VlmWhw2EJmrFsI859cAL+8N/56ZoUus7bGYvzdMkLkgns+2z8AnPv6UmJ\n5Mi5As01aOWmFjz07uf41hPRlhCLI2i8yEN9YmDmdUVsV2Appu7rxksB0axcTsLEkvPnzpTcVO8X\nR2A5fr9v9Gd5uan8zq7fGocmGJOxZK3dojbjSjXOTucaWAD+8dFSZXEX9dBVLUg65zbOuEOZCP/g\nszVaomjlpm349Uuf4r7ROZH4nScn46S731VshPKusnStTw+tpcglpnI1fvefWdjz+lyesFWb0v0u\nLuuTCvNXN2Hota9lXejFtFi0FFUA5zB569inK273bCGoGCbK2VJlQ2GliP2QLIWw6ozQ03Q2sWB5\nrBth1g6naJDFSk1auC67ELT7XnK27d535uO8hyZk/47DImj6PlVtYpAglmWlv/aFmfju39QWR9a1\n+i3b0IwRN/+37OIZZId56eMfhYoi5/mx81fZFOONuGt9LQCgpSO+B7ZlWTjr/nF4dcYKbJEs7xTE\nXycuydYB5O4RHZFs+gE47rO0Zeq1GS5XZczXa96qJuzzmzfxyvQV8e4oZuxrWejp8rusUcbmQrqI\nEOn8dXaqo3KCwkqRnCsw2vY9G+qi7zvCG4gtjJS3VIz5yQ7Ejt/bO72FL3j0Q5z/cPCUd5l4iyXG\nyvADQLWJOpetLTObcZ2i1Uxp7oCj0EufLDe2nqObWC1WRd4uu33Ykk4pK9BqlrNYxWsJmb5sE370\nzCc44Ia3sKBR37WZc+2n/41yKcvBcxN0OWetSCdaHiNZbmtB4xZ8/ZGJ0nVJC2uPGREkI8lJR3Vb\ndvI97+HgG9+JpS1xQmGliH1jRnmI/OvKo3HHeQdF3ne04HX1si3tKSxZnz+jTrZ5XlyVdoucdftv\nHceQUKp8TrquQB2SZC4vtitQxnMfL8VfJyyWnsc4mvfI+wtx0t3v+qZiaKjLWKxidAW6X2j82vLm\np6uy4sFNro8mqENlybWptaMTEz8v/lpzt78xBx8tWm80zsuJUVeg6xKu2LgNzW3mBGGU2NhCZzur\nrNaRRCisFMnGWIXcCUftvr3nu8OHbo8udblTPahvN619R7JYaXZot3VJtr2zGTr1u4Miix4CoLi/\nZRuaccXfJhe8dIpN0HVznz7t4PUEPQjjfEFWPcpfPj8TN/xnVm47x4buN3gTzZ2ciQNaviGdj62l\nvRO/fmlmdhalHTJQaKxjEDe+OivvbzuHm/t4r3xqCkbdl78UTi4fXRq7q9oiOVH9C8DvX5mNb/z5\nQ8xf7Y0BW7FxG96bH7ySR6F91LQVqBgvRsfcPgYX/XmScvlsn9CcjBREQS/gyemC2lBYKaLqCvR7\ne3cmSferw2/pGp/Y8EBSKeDT5ZsiT/f2s1jZnb2QB0bgpiEn2Iog7lRbesvrc/D27NV4d15jYFNU\n6wtqnmdWoG5CV0nxUrzRA3q53W55bTauUIwjA6KkodArb4rnpy7DUx8uxd1vzwOQOyfO+ySVsjDB\noOXj/fn5dU1cqH79s7MnXa5A53rvTS3twS8HRRRf8zNB9Rsl6T+OuX0MvvXER9kYLRmB92LE3wrB\nrtbkTDyZO7ccc9Ql2JOpDIWVInanDQte9+sUTsHlJ778brIowesfL16PM/40Dpf95WPtbQH5gJKy\nHLFbBQw4hbgCowzmkZe08Y0zU9s+SHzKlhAqlF+/lL/eYLFEhs7b/J8/WJSdpq+C9vW2hYJznUu9\nGpzVKGPrD/ua2/ey8xo8Nm4hLnpsEsbMVT9+HezFvlWO175mdnvt82W3O5UCDvzd2/jVCzPNNzQm\nHhi7oKDtpTOPA34zgezWWdBY2MzMuIRJpETVrm0qQTSpQGGliOqSNn7iyCnIfLWZz/dRrEOL1hWY\no0eyy6uemZr97GyT+5Q4y0mrDjgcZ10dnSn89B+fYP7qplAzdRLREcRJs8zoCBrTMVaLHUHhUY+z\npT0Vanl0cs6D4/NSURR6fm3Lj/M+sYPdV24yEzeydL18pQE/gl4wcq5A++/0F89PXRapbabJCpyA\naxmn29W0IAhq6m2ONVq16izw9Sz0GEOqv/2NuXmpc6oZCitFbJN4jY8qOm3/nfDTU/bCzn27Sn+v\nVbBY+RElj1WhY4zsJn1n9mqP60CGe7q0N92Cv9XLKUznr96Cl6atwE+e/ST73f9lEhjqYOV9Ljxw\nXtkFGegKzCdr6VBshMogWixXjemX0BNV80tJcB6zn2VMdo4/WboxUioKvzNck7UISfavcMZWbWpB\na4ypGryuwHw/ks74UYxZaCqz6OLQVSaWmtrW1uk7O9TkmYsj6Whe/SHjycPvfZ6XOke2TVxtSxrR\ncwBUGdk8Vj6DyMOXHgYgfRO9MXMVmlzTc52CzG8c8utyM5bLZ/TESZgbzERQYpQ6osyyUh0b1zSp\npSMwMX67B+ygt+1XZ6zAT/8xDZ/+/iuO7fX2F+fDrybG17NCMtLH/aAJwu1q0+Wo20Zj1x26m2yS\nK6A//e8Hn63BqfvvFJrMtxyIw2KlYikLY9/fvonuXWox+8bTjLTJDxNtDay/yJ2hnLwTbmixUuSb\nRw9F9y61GLnPjoHlunWpxVmH7Oz5vs4hrHT7Syk6mN8u7e+dwkD3Rra3lA2EzW0d+P7fJytlIFcO\nIpd8J2vyVtdsQN/jsoCR97yLZyYtVWxBOEFGyTvfnIeOlIXVhqcem5r9GKdo0+37p/3xfefWAOKN\n6/Cr2r7dVZZ+8mOJz6LifuzYq0G5rC02r/h7ej1LP2tEHIuDq6K7a1VhtXpzS9GPq9l1r8VpTS48\nQai5tjHGigSy78DemH3jadipj9zV50T2huy0WPm59pLU6fwGnv/3r+kA8oVAmEXA/tUTJyXZxc2v\nzcFbs1ZHcvkVCwvAwjVb8asX/QN7Zy4LtjK6Dz3r6lB2BSqUybPeeLcwlTA0SQlCnesB2ofsFpDF\nsGBlXYESA2vc97nSbFaPez79r2w2o5PlG7dhnd1vijg5Qi3GKryu+aubcOSto/GX8Yuz3wVtFpfV\n01I5IACPj1sU+Pv789egsaklU2ehFyTYDaxb+5qmVnz5/96L3poEPQ91obAqEk4Xol8HTZL/Oewm\n0smtZVs0snEdmdrD3jBN3ViyAeelafrLgATVt3pzC57IDIJfrG/G/9w/zlMmvw7536pjo4k3bt0q\nGpta8B/Jsh+ql2nDVv2lKUwcZ1jMlnMfSzNWItW3dv8Yq/S/qQIsVroUUr19O9v3ql9dx94+Bofd\n/N+8MsUYtXLnzn9vzuvY3pnCDS9/6nHv2xMIJuimJonpIMOqvenV2YGW5W8+8VE2B2FOq8UUY6XZ\ngV+ethxfrN8WS1uSDoVVDMj6tXNWoJ+gSJJCD7uHdPKj2EG4whUYWyxrvN9ugvLe6Nb3/b9PwY2v\nzsaSdVvR3qkQB+YWVgbaoFvG2Q9Xb27Js2DJRP63nvgYP3n2E09uNNs68/Hi9fg0IB7wkJvCl6Zw\nrwtmIpZPp9wJd43Npi0oZGdBMVZRbnMV17gtIvxe0PLc9wG/pf/Wa58KKzdtwxszV4YXDKAzZWFz\nizw3n3MW7ug5jfjrxCW44T+fSsuq9qy4hiiT9douY784OVPotjnJS+vEDYVVkXC6S/wSfiapG5r0\ns2/elrYMuY+v0Azsv39ldqjLDTAfJyKrzhYEKSu3AK8O2rMCDRyS86F/5K2jMSJjiQDk13/lpvTb\np9taWSPSy6mc//BEnPGnYEudDKcVzL0umPs4lUSrvW3EPuxeA9BC+phl/SgsxipvtYIC7qkjbh0d\neVsZnpm69veub0zeOV97aCJ+8PRU3/vRr01OfvbcNBz0u7el2zsX27b34R5r3S93+T96v5LNRlzQ\nuAUfZzLvR0bjfrdg4Yv1zdn7z7/KwpRVWFsCZzkrDkhJesbFCYVVDMg6j9Ni5dcJe3ZN0CRNjRE1\n9IZ0VZZNtxCwE/fsrk+Wyq0IY+d5F07VZe6q/IR8FtJxcDN8RJus3SnHmKZmTSrQQqBQPnQhYc19\n+qZfEwKTNLJ+u5n4eYDl0Mo/jtkr5OvhSTdVtVh5/vZuuMevXsf3NDLGZxNt+jTi23/5CO+HLMMS\nFZUYK7dVyx3j57Qqt7R34tmPlioLIj+Wb9yWV3cYrZkZwM57yq5DRp7b1adM1JcsW5B9uHAdTrn3\nPZz/8ETMW1VYIk9ALfzDsoDj7xyLo28b4/reNYYU3JroyFPnmK+zXKCwigGZCTTfFejdpk+3etx3\n4SFxNkuLZQEDmC7u47X/DLtx7NPY3O4fC2VZwJufrsToOf7ZrIP24xdn1RKQQ0h2/bKZq4Xa4B1H\nnrEotZhAiHCzf9ByO8H5vqy83/84+rPs5wWNWwLf4v2q3eq65jI3mPOrDz5LC6D/zlEX8XYKClks\n4qszVuLdeWvw/cyMvFLgzS2X+d4OYHb8du8783HdCzPx1qxVRvat2uuu/kc6f12n+4Igfc3ck4Bk\n57rQZancfNa4Jfs56nJhQfvvTFn4YkNzaNkHxi7Abte9nvddLut/YfiKUgPjhYoIrwSrVoJMJJWN\ncx1AWQf9/pd2R3+N6dJxc+6DE8ILKeL/NqxqPg6+1a58Sj3Tu9s69dgHCyX7C0bWbvur8x6aiBd/\neExIDepYliXNsG0ij5WGV83TJicqswK/8ecPfX8LW/rHGTszZm5O3Jxyb3rG0eLbR4Xu38kLnyzP\n+9tjsbLyv1u7RT/oXuZysj+Py6wXWMoQFN98VZI0EXbsXVNLtMkebtJ1hx/8woxLVjaL+ryHJmDq\n0o15194prExZO4K8azprZPrW66jjpLvf9bih02W9B/PUh0s839luz6ixTaFbuV+QLStwskMVh1jR\nYlUsGupycTd+LphyDfYLFSLZcvnukUJjrADgbxMXh5ZxCtlH3ssXUo++7xVWYbR3+gsr1RQGfofu\nFpHO9AEq2zsJcpsA+gkVw2aMxUHKsvJiZ3SIErwOmDm+XOb15PgzgpritnbI3IZeARrxumiWb+1I\neRIuT5WEBnToWKzyZmuGt0hWj98qHDo4a5CJKsBHtEjLxdvXgmovZb6zJEJhVSS61udO9XmH7uL5\nXSQq2YIeYYIwl7Ml87f9veJAEPRwWqcwhd9PwL34iXwdtChDhO7Aolre79hVtv/RM58E/q4trHy+\nL3RQDXYFAh1+sz3C6o34oNE5Hr+S9jM3z4riKlPK+z3snnVaiUy/78n63erNLXlrRDpZuakFC9eE\nr32ayjvX8T/oC8nfptM+afySZN+xzwr0WKyi1FKuTzk9KKxiQHa/OWeK7bJdN9x89gFK25UDfm9a\nftg3ZJDFynnTLttQWLyX34PyrVmrPRmRdXnxk2VoamnPGyZVBhzVMck/3qFwouoh+UAfVD54R8Fv\nwohssVI9SZ6JBNH2BiB3HmokrkBv2eLe8M7jdO/Z3V5pswvsdEELqR9562j8daLXvaWD1GLll3pC\nsc5s7CS8jTftCgxohBJhM4sty0KHUioYtR1aPp9tCo/1Kl8rGIVVDMhu5oa63KmuEQLnj/BarSod\nz1TuIt03OslMAb0B4WfPTce1z8+M7Vj8RInq/iYsWItlG+RLo0R1U+kKkbDdhAWvyx6YKig/PCWx\nI6r4z5RM/xvlHBdqAXQKNt1p8Nlra3l/89+fetsA4DtPfqy3gSJ5qS1Mx1jJXIEFWazsesPrUO1D\nuZnJ8jqfmrQUe17/hm9ONN3Z3Xm/la8GigUKqxhwuv1snDeQEPkxV/Z35esMVCNq8Hqh6Bo8dFu1\nanML1m11LKWiUIPfoS9d35zv0nCUC1veQsZFj03KBnm7UdUrqZSF216fk3W76roE7nlnXuDvgf3A\niu4KjIpkEpo29kPXGXivWqeJ2ENZXXn797VqZP51Fs268AsUfJl/w7KeT1qkniMq9KXJ9JDqGseL\ngfoLQnDc2CuZfHGfK7hV5fX7709GoRbZcn4eUljFQK+u9YG/10o6nED5ugJV+HDhOrRk8tI4c+QE\nYerGiiLgdDbZ1taZF9Cu5gr0L7TS8UbprOtvDleJe3t3CgEnLe0p6TlQeRMWApi6dAMecQT5u7ez\nYAVeqQfGfh66Hz8sRHcFql53neD1to4UFjQ2hZaVJQh1E1fMmrNeZ11Oy59730EWtmzwuuH3oLvf\nmof7x3zm+X7OSvVcZX/IW1PUP57NjdSdDYG73pqLode+ln258cQt5bkCizNgS6+JZNe5ZYnkx2eH\nowSlkgHSC0bPWOadHBDosleUf1FPmfue+GJ9s7SNSYHpFmKgl0+izxP27o/3569B9wZvZu5KFlUA\ncOGjuen29kARaFo26F/XdQWm96/Otnb3yvWF7UAmvMO2n7tK/WGUrULxIN3nL+x0/vG/n2Frm/rU\n/LAYqyjXL6ze/HIuoRiw4Yl3jcWKTS04cFAfAOmg6wsemYhj9+yXVy4nRpwPe/3Ylfx26Z8H56m7\n7fU5ufa5+ph75p+K6C70Dr1/7AIAwI9G7uX5zW+hejdhGdB9xavP9/Ys4Y6UhS41InfNFF2BzW0d\neH7qclxy5JBAi43OpVSf3RpcsGsmHKW1PVhY3fbGXADA9N+eij7d/Y0EeTFWMqEa5lr0C3OQls2v\n7/g7xwLQT7VSLCisYqB7F/mSJtsyD5seXeSnvdLFlRuTLo8gosRYmYiz8cOyrDwXkZt3HMlO/R7G\n7m9DPSKSzhU5xirExPN/eVaECPU5aO3ojOwKfGX6ikBLnm97AiTDik1pa6K9Xt2j7y/E0vXNaHQt\n9msnCJ26ZAMuPWpX+UPWp+P4XZePF28IaXlwXU4Xm6c5Hje9ty6/s6JqWRZ+phQJhebM8iZ9DXqJ\nyyEyed597w3HiZMFr9/6+hw89eFS/OalT/H+L07CkB26B7ZT6R1K0hbZhJ785ZO82BYr94ugHy0d\nneiDnLAysZ5kvjVVXkb2fUfKwt8nLMYFhw9Gz4bkyxa6AmPA72bZ2pru0H7CKwl5rO4478DY96Hz\nVmxkf5q7sVDY23iYKPvTmAWe5Smc/Oal3MKxfoLJvQvVN3zdbSzLey6kuspAIK+Mm16dHTl4PWWp\nZUuXx4wF7zM3szX9wXn0qZSFZz/6AgDw0rQV+PcUeVoPf1eg/HsdK6CsrqBFmN35q/JmEAbM5tNB\np4cUeqzZfQb0y7aOFHa/7jU877w+ruKeOp3nUFL3ekf6lw8W+C9ZpJVuQbWcT4zV0GvTx2jH/tpL\nBbkJE8i619/krMAxcxtx06uzcctrswustThQWMWAXwe13xR6SBR3sfz1YRSjHVlBFXKjmnIHRpuZ\npV7WbX0KS+Hwj4+WarTDz2Kl556TEdViaFoQB1U3b3VT9HQLqvt3/f2iKzN74Lb2xpnbZk1TK2a5\n1jO0M4gXnK4gwja691B28WLHZv/4+ItIdQXxYcjaklH2pLONZVnYuK0NKSs4WD53eeUpOSOT9TDG\nMCtQCE/LHnn/c0fSWvn2L0/z9vsxc1fjVy/OlJaP0h/yZqz6lJHVa1ueNxvK/h83FFYx4KdNmjNv\nYTKLlRDJmANRFIHnetv3LWZoHA9yu5nA/eD/1hMfBZbXsUz6tXzRmq15gb9hg9xdb3ln5kUNkvas\n/Rihmh89MzXrog3aXEBEtlip4j4PU5ZsCBWd7vNtX9G3Zq1WfhD69YOCLUOOav3cQ6H7VmhDIe10\nxlzK6y6CNVuyi9ykA9f1Vbxlta06Sq5A1X17rafZ/Ti+/dWLM/HObO/aqm7RYlnAd56cjGcmLZW2\nY6xjealCL9faLa3ZWYuyuuyxIgnPSBUorIqIbcmQW6ySEWNVa2CZhjDstdqC7kXLSs/8MMEnkuUv\nQtEYKNyDsEo2eOVm+LTjoscm4e6352ddD1EGNlW94nE7as4KlPHqjJVYkVlyJ+ghWiOA9qiLGioi\n2/t6xWuYWwcz/Ay49+O3iZ8w0xHkzW0duOSxSb7ZzN01qbjnTQq+MKLsS0eMffDZWp+kli6rTkCV\nT324NLIADLPYOdG1WAHe8+c+9899HG41D3tZu/KpqZjw+Vr/sqErcuS2ufyvk/HjZz/B+q1t0r12\nBtxnm7a149535kee5BIHFFYx4DcAbgsQVgKFpxcYuc+OBW0PmFn/SpWw++CKv08pTkMk6Ji5V26S\nJ9zzQ+8Bozqo6g8qqukWmjKB2rk2IfBvXYI2rxHCNyYkCbg8gXnfFVqnG9VuIwQwdu4ajFuwFmf8\naZy0Yv/s3HbR5DykCiHonAWJD/u+W7k5Lf5XS5JqPjlhMd7/bK1vHUFMX7YptH1+7VQh7PqpiPSX\nPlkRWueGre2e71Rx1rY8E4zfkZKnhrFFk+zxdPOrs3Hf6M/wzuxVkdtiGgqrGLCv/an7DcDcm07L\nfm+7NLrVe12BNTWiYIuVCU1UTKOZ6kydUvDhQvUkhbpoCSvFctFirMI3emnaCo/ANe6mCaiupkag\nNSTvTiFM+HxtxNlNtmXDfpPO/aYqcjc2t2OVRJSbOL+ysUDuvMz/MWe5Ct7eaR0odNw658Hx3n1F\nEhP+26tWl8vnlf73i/XpB/7V/5gmLb/NFU9ZUlegM4+XRzS602uEc8ebc0PbETSxQe6S9MNbgbPO\nIFdgcyZ2uT3mWEwdKKxiwO5s9bU1eWsEPvbNEfjK/gOk7rYaAzFW14/ar8AaiuuODLoNPlmqP7Xc\nJD94Oj5rmc6VDhtU7ZoiBegrlFnjSiOQ3pd+PdL9W+l4j9dmrvQtIwC0dsRnsVq0dmukA7AfYhub\n02/sKrGJMsF03kMTPN/5iWSde1NmkRB5v8u3s9soFXeO7/78wULv72Ft8un3Mle9KYtZ4BqWkn3k\n1kxMzkNaOf9ZQDGB/HOhG0vb3pmSxqq6Z5PqkD9j1a7PG3hv7x8ItrQl54oxj1Us5JLt5V/qU/Yb\ngFP2GyDdptCg8W8fMxS79etRUB3FXlYnaPAq9dtHnOOqnsVK+XVVG1m6hc/XbMEe/XsGbyfJERSl\n+6YsKxsY60eNCLdYNUeYmm+THsgjiNLMJjLRp9N3lm/05iP63X9mabfHTbjFyv2bLajCywLpyRPa\nxB5j5fjsY5+7+bU50vLucnGE61iWBcvKD7dQmxWY+7x2Syt26NEleD+S79z3Z42mSWWv69/Azn26\nhtYb9puvoM/8O3nx+qwxwlm2LSusvNu+NsP/xaxU0GIVA1HyvtSkg6w8PHfFUUrbm3jDsqziWqyC\n8j4WMdSr6OiI6B8+PTXw90IW+5U9POxYkqDqorpZPPUolBHCP++OTVh6i7D6zYtoeYWqu/FL96Cc\niBMick48t8By8pEjQWl7KhWrhSBK3Zu2tefNVAOCLSqBQjOGN6ubXp2D3X/1en4+MYXL5LQOjrj5\nv3jsg0XSckGuUPeYE+UFeoU0ljS6hU/2QvODp6dimeRloy3zApOUtERhUFjFQBT3jJ+1SHWWnqlh\noKgxVgGtTkKy1LjQObKFipYBUzFWdQqvsu7t2iO66lQG47mrmrChOThAtpBnoKlelpefR6M9dRpv\nEM8qzOQC0g8hqcUqL4Gk+7f0v/NXb/Gt154OD3hTjHy4cJ1RMRK1rsue/BiplIVNIX3GF1eMladd\nIZuPnuufkPaJ8XJBFIbbqjt2nnwfQcsnuYdT08OrztV6fsoyDL32tWzCbCC/7Y9J3My2K3DKktKG\niKhCYRUDUTqtEPLgdVtYDdk+eGkEUxQ1xiooJqBydVUs6jWKxUom2mozI0Lw23z+31f8fUqsLmR3\nEK2bhWv8xUAYQhQeHwIAGxzpGXTqc744pVIWnp60xLesqsujqaVd+mZv+fx1x5tztR/6zmWGXpm+\nEhc++iH+OfmLwG2KdUvfP3YBfvdKOkN30Aua7AEeFGN1wA1v4Y2ZwTPP2hReMgrVn2FpBWyXYxDu\n/hFVyAa6An2u+AOZNSKdEzece1+yzptmxz6vi3zShyQNxljFgn1zqm/hF7xuD7z2cgR+mHtZLGa6\nBf9Gl4vJt9RsbG5H3+5dIi1pIxMstRmLVVB/kl23uILnVbggJNlkaDsMpKpYJZmObyOQzov18rQV\nnt+cwurfU5fh+hc/9ZTRpam1Q+s2fujdz7X30dZhoVsm1Gfp+vTDTvZAjEohfePNT3PiZ+6qJjz4\n7gJpub+MX5z3tzPAW3Y7bWntwERX/qn35jeiua0D5x66i3L7Cu33ft01qF63wHRaNBc0bon8cpJ1\ntSoelHCEvDjvoY0SC6OzTpWY2yRNOKDFKgayMVYa26QThMpnCwLhHTeuWTQ3nrW/kXplBL15VbKs\nMikaT7z7Xbz56Spj2clr7f4W0J9kIuq5j4OtFTKSMBD6zUIKI+h8yw5r7qrN3i+Rjg/b2Jy2dm3e\nFj0nkJPW9pS0j5kUPs58Q7b70LnLzS3tyklWZSg/qCUjhbMdc1Zuxp1vztN+8VQdT5/96Av87z+n\n69UtaYxOElzflxhL+hGAdzy1+8fmlnaccu97hecMlE0E8BnmdMUYkAteLxcorGIkrOPcdm5uwWO/\nh21WWBW4L1XcrYhT4ARpgUq2WJk+skmL1hnLOmyHWAUGr0u+8xMOiSdi8HpHwEAve3AGuUoPvvEd\n/dhQ9WYAACAASURBVAYEcN5hu4RO/ih0vJCt3+i8Z4+8ZTQOvSn/uPRuabUGygSQbD+qQinOWYHS\n/WUau9f1byhvo7JEl7sPes6JAGav2IyDfve28n5l6MbCOidW6BgDVFysSYLCKgYcYayB5S48fDBG\nHTQwvY2QP3CLHbxeX1u8LhHkPiq3NxQdCpnFJsPkenrjMpmkA5O3St+4I7gCS2+wAhDN2ht0vGNc\nAcwqtZu03jXU1YS+mBS6kLbMwiKQjndbuGZLdsH5/N/VH8Km+4bq7ZFdqDhGZeWsOcpLln9gvTN4\nPR+ZxWp1k96KETJysy69jZK595zoXOO4l7UyDWOsYkAouu+EI3K2xid43dZVxXKbNNS5hFWMlqMg\nK0u5BCkmASGAzqDcFRrc9sZcfP9LewT2XVNjXBJ0VdTe3RFwvh95Xz95ZkfKwnvz10RsjZew4wqb\naRmG9N4VAiPvea+gem1M9w2tGCCN8nG2xX97eQVB9bqFdo0w6xWQ7Vs66cRhQJi+TH0N13ITVrRY\nxUBQ7hQ3ttJPB6/L4gUUY6wMDQQNriD5OB1ypqwspnn4Pf1g3lIiYPZcXvr4JNzzznzf3wu1dtgk\nYdFU58uNDjptdwZF+7HX9W/gA9e6c1F5feZKrDW4ELgMWR+QGdefjJhioLAUGrKTHV5h3lqBBqSd\nioUuirYJnxXoPX/p/eR2Jn/a6FOINvvty+qJcE1b+eOGwioGhIaVyX7x9UsQqh4Irz8QnCrJAu/O\nYxRnqFOc5vZCmJFZIDUuTAuKtMXKXJ1hD3hT1+0GjYE1TqIcja7rs5gRg41NrfjJs5/Eug/Z0cse\n1fePzb2kxLLigITPGps836l3WaFZPscGl5j1Owbn91H6hd+9nve4CWl/TY0Zi5UQwG2vz8G/pyzT\n2kYV24OyydDEjmJBV2AM6MwKzC3iKu9tuRkU4W8pushuLPdXcWqf9oQKq7gxZfGxqRGiqNYfleBZ\nFT5aHN9C16oImHf79Gyow5bW6MvslAOWJYnjkQxhURfQLmRWYIskU7/qPRd1JYM735zrmzHfTVx5\nrNZnZpdamf858SzC7BN6oouAiOT6VqVPt3o0NrVGT/haImixioHsWoEKN9CwnXoBAAb0bpDXpdj7\no9ysKoHxcVqVgmZWVTLGT6lhi1UYSXDhmSLtCTQtdI1Wl0jkFisvzrUUdU6L6nhmYoFiJ1FSAQDA\ng+9+jpWuJV/iSporc/u/Mn0Frvn3jOzfHlcggv8uJjrnpVuX9LqB5eYKpMUqDjQsVlefvBdOHNYf\nhwzZTmruVI3Xcg8wO/ZqQGNTa3AzJf27oa427+84H6KyKdvVgOmJCCZnBapg2uJWagrJtyRDurhv\npaUPkaWUkBxi1GnypsWursVqzNzVBVsdVY4hmhvae05/7HD9ypYl8izCLIQZS63kmk9evF6aDNev\nLSooncsEDUsUVjGg6r4DgLraGhy26/b+dUU0Te/Up2uosJK5Avce0DPv7zgfouU208MUplxpNqZj\nrMKopMvW0Wlh1H3jjNYpu2e+/shEo/soNVb2/3KEiUcdcWl62GlqURNJ9ph46+vByygVQtxL2gCy\ndAveWYFGxKukiq89HNDXEyR+4oSuwBgw+XaqajaNFmMl2V8R36yTOiswbowHr6O41r9KcgW2G0pT\n4aRyzo4/MvF411vzStASs5gc/fzG7qhxZzZRlnfxLsJs5khbJPnKTJEXi19mNxWFVQxE9dMHLQvg\nrOurB+6EI4bmW7m8byjh1CgEg8TZoZeuN7fERjlh+pymg9eLZ0aqNFegaarh/MSd3FFVfMS5+Heh\n+FmEnJn2o3QVlXtdNrHAqaVExBUH3MgSwQa3y4ok6vzuqX9GWEqrGNAVGAOFvgz07lqHzS7TtbNf\nPXjxYQCAode+BgDYb2BvXHXSntr7UZluazrWgZiPsZq4cB2WrCteQtVKsljF8WB2n54khlf169mA\ntVuCQwWC0OnCKze2YPG6rVoxS+c9VHzXqXO5FROkUlZ2jA7ijD99oFVvFEu/1xVo5jh1hdXyDduM\nppi45vkZ0u9LDS1WMZCdFWhAlPTtXg8AOOeQQZ7fDh3SFwDw+tXHY7d+PbTrrvW5uR659LDs5yp4\n+TaG6mww0zFWU5ZswNot8SaEdFJJFpk4XhzcwjmJp6tfzy4FbW9B/dz95uVPIy3SrdYOcyd32cZm\nbaEQRKti4P6ny/XW2VSKsQoR9zXR8uJ62KY5W+83Grnr6hwDqlpcWXJuNAqrGMgGnGtawO2s52cM\n3zn7Xa+u9Zhz42n43y/v7Sn/ryuPwYJbTg9uRAA1Plf/gEF9whtLPKi+BZa7waeShFUc18IdA/Pg\nu8nL5F+oZUbH6vre/DWJeuj5MX7BOqMzRFWSZkY5KyrxlGF5rGqEwLee+CjC3vOJEmOl2vWc6YCc\n3a1Yy7sVAl2BMRB1yOpaX4tpv/0yejbU4ZlJS7Pf27k83NT6pWtXxG9wdVpekt+Fk4PqgJHUjPOq\nVNKswESak4pAoY4gywI+k0zr96OIIYCJYe4qbwZ4EygtUB+Sx8qUB9ykhc/NorVbsWzDNgD5Vv5y\nuGVpsYqDbB4r/R7Qt3sX1NXWYOQ+OxpulBc/11WSA0KTTJAVYN7Np2U/l7vFp9yFoZMpSzaUugkl\nodA+aMHCZ43qwqocLFaVhDsOa0NzG5odMW6mYqyiDAWqu7ZFFZDvClzd1CIrnigorGJAJ/O6H49c\nehhm/O7UyNv/39eHh5bxu7nyFiPleKhMUIyVcw3G7boXFt9SakzHiJWSlwISGVYyhV5CWRJK0/tT\niQP7cGHpl0UqhJtenR1LvW534Yxlm/L6uqnVAaJc1ygv7s79HH3bGGNtiQsKqxjQWSvQj/raGvTu\nWh95+93798SXJYssO1Hp3hYsPP+Do3GmI+6LyAkaMJwD2SGZSQflSrlb3EjxLUhR9uZeEJ6o09YZ\n7KIz5ZWI0o+iGMvK7WWOPTcGdDKvlxI/15W72Yftuj369ZSvZVgMjt59h5LtW4egAcN5rqcv21SE\n1sRHJbkCq5ViX8IoY+Gqzcl3+SSVsJQM5baepcqswCSlNaGwioH+vdIiZPgupbVMRNV1zreQJGjD\nHg3y4P2koRq3kKD7PxLVmjG/kii21TEJ40g1ETZZYMy8RjM7inBdZ8T0YpmkPsZZgTGwe/+eeP0n\nx2Mv17p7xSe4p/npgCR10HJC9S0wSW9WUaikBKHVysI1xUsoC3B2cbEZt2BN4O+6ubP84HWVQ4tV\nTOy3c2/U1yb79Pr52Qu9Wf515dF45UfHAZAnNq1UVHMDlWLW5azff8VYXRTeRJekh0VUGnEuIu3k\n0fcXFmU/5QYtVlWMv8XK8nxWCVLs1bUOk399Chrq0q67xbePwseL1+PFT5YX3tgyIMkWq1qDQRXl\nFkhKSg97DKkmkm1SIbFyuGshZ5v8LLfq9dUIkRVVue+itMwce/TXX+pHB6dgUY2xKvegXLoCiS7U\n4iRuktTHKKzKiAsPH6xVPqyjnXbATpj861Ow38Deed/37hYtzYNcV5RWWcU9Zfv4vfplP6taopzX\n5aBdirN8kEkrGWcFEl3YY0g1QWFVRtx+3kFYfPsoo3U60ygM6tsNANCnWz2+cYSeiPPDhMUqSW8i\nbpwLWUdZf+2Xp+1jsjm+mMq0DNAVSPRZsDqe5V0ISSKMsapCHr7kMLR2eBPIPXLpYdnPO/RICy77\nEaryLJU9uk0+0KMQ5+4vPnIIfnLyXjjy1tEAoonIYk1wMHkaaLAiuqzYVN7ub5J8kjQs0WJVwfh1\ntD137IGzDh4UWC6KIJFZbEwIq6SmJ7jlnAMxoHfXbPuizParqy3OwQkhjGXPpyuQEJI0kjTzlMKq\nCunTLX8NLrtDOgVMLnt8YfsyIYoKaUOXuvi7uC0eo1isimXREzD3RtcS44r2hBASheTIKgqrquKa\n04Zh/LUjs5nh3eRZXDIPfJ21oGQSwbRuuPGs/fHyVccql69zqZ0nLzvcU6bQHE/2Hm477yDtbYs1\na9LkdXhs3CJzlRFCiAFosSJFwd3R6mpENkBdvY7g3/9++RHZz7KHt9Mic6hr8eG3f3YCjvBJ+SDj\n4UsOwzePHorhg9WXCnLHMJ04bEdPmR4NhYUa2oe478Be2HNHvWz7AgIPX3JoQftX2k9S/amEEGKA\nBOkqCqtqIiwGSOYKDOO4PfsF/u4UVi/8MN/StPeAXhiyQ3fFPUWjGMHhtmgREHmzBG1sMfurr3pn\nAAoBbNe9i+f7OEjSGx0hpDD4rpRPkkI/KawqjOeuOAoPXZy2gJxtYDmZsL6abwmRBa+r7efkfbyW\nJO++wusZ6hJqxQgOt/dQI+QZzk87YCcAwHF79vduK2hNIoTow1EjH52wlbihsKowjtx9B5x+4EAA\nwFkHD8JX9h+Q/S3SossaVo7B23vdjKqiYZ+BvULLqNQ0sE9+G+pra2J/s8vOChQicOkYd67S8w7d\nBcMG9Iq1fc4Ys+QMO/HRo0tteKEKRMc9TiqDUqeySRq0WJGioZIC4NBd04NyH0fG9Sj37OPf8gaG\nq1qsgvSb/ZOKSHMXqS+Cxaom6wqUW6zsb9xuwnu+Phx1tTWxBbDv0b8H5t18OubceFo8O0ggE649\nGd3qq09c8RFbfVBYuUhQqAOFVYWjcu/97sz98fpPjsfOjsB2W5DpdNXte3hjhVQtVir7iTKMHL1H\ncAxYVJxB6llh5eMKtPE/F/EMkKN/fiJqawS6VZEVp0/3euzUp2upm1F0+IytPnjN80mOrKKwqnjy\nAtJ97sSGulrst3P+eoHuonbg86VH7YoPrztZef8mLFY644fd7pP32RE3nX0ALjlyiNJ2L2mkcLDr\nz+4z+6/cFZhzFcrr0h0gd44qHJI08hCj8BlbfVBY5ZOkxMUUVhVOlGzgTtyCZ4/+PTCgtzwPloww\nc7Vdf1Dgoc7tYh/vHjv2xKVH7apsMTtYM0Ylr02OXbjzZuVt46Meda/QX79zRHgh2f6rRFmV2/Nm\np96FW9g4AaL6KNZyWOVCkkY3XplKJ+J4G7SZziAeVtR+2HetC3dXqezWxPOlu6brzBaPFiwfi1X6\nu85U8PbK+4sYlNUZ4xtd0p/rOi8DxaZYSWJVSPJ5Ivk0FGFViXIiQQYrCqtKxzlmh+Wcytsus6Et\nfKL2WVXRsGPvBjzx7RHY3+WSdOI2+Jw0zJu+wCY4CUQwQXFSubbkGmMfYsoC+kpyUtm1+QkbXWEl\ny5Wlgp+wM0HUNhWLQi23bhbfPspYXSasTaZylDEgunzoQotVHknK08crU+HYg/YfLzwYw3YKT2ng\n3s7dV3UfAqrFBQRG7jMAf/3OETg9k/cpiMW3j8JfLovmEvPjjauPx01nH+BRkbefe2DgdsMGpM9r\nXa3AzWcd4Fsu5ecK1HyWBQk/v+WKgvZvgqhWNB10YvvKCXcajlJCWVU+FGMd1HIiQboqXFgJIZ4Q\nQjQKIT4NKHOiEGKaEGKWEOI9s00khWAPlHF0ui/t7W8xslF9A7aL9evZgK8fPjiwjFqFGmUz7Duw\nNy49atfs36/86Dj88/tH48IjvAHwzvP56DdH4OnvHoneXevRp3s9znUnZs20xZnOwonuMjhBIsbZ\nfjcdMdrKi+HOUp7tV2bqwLQ1rRDijNWqxjQYcUJhlU+SYkhVrsyTAHwT4Qgh+gJ4EMCZlmXtD+B8\nM00jJrAfeFE7nd9WE64diUcuPSx0e3WLVY7Ozug3iOzBEPVhMWSH7jhit/C1DPt0q8exCm7WwdvL\nl+/pWl+LJ749Al3r1QZKp9ttiE+dMuKcNSNzBQ7ZvruRwOxKJ0netzjbkqRYskqAwev5lJXFyrKs\n9wGsDyhyEYAXLMtaminfaKhtxAB2RmadB7AKO/fthq4Kb6ChFqvMzeAsduKw/vje8bvlikS4Y0xY\nAYKafsUJuxtty8h9BuD5HxyjVJ/zAaXzIIwzeF1mRbv93APRvYFWijBM6A1TlzZOYcWZi2ahxSqf\nSgte3xvAdkKId4UQU4QQ3zRQJzHEt48Zind+dgIO2zXc8iKj0LcAZVeg4/FSV1uD60ftF2l/Knt7\n/FsjcNfXDgotF3TsOwZZYiI+P1TPlVPEHD40/7oG1VCIsBoY4oaTxX2lrNJ45crt8V1qwXHqfo5l\nr2I8e+V2XZIOLVb5lJsrMIw6AIcBGAXgKwB+I4TYW1ZQCHGFEGKyEGLymjVrDOyahCGEwF4D1IPW\nc9ul/y20syoPphFH3Yt9EoDmJUZ1/XbyvgOyCyPHye79e3jaEoS7nN+sH6fb7fLjdsv7LehqdRag\nksP6kMwVaMHiLDMFTJyiQu7SLzlm18bprmNXMEvSZ+Ka4ASFOF6bsnIFKrAMwFuWZW21LGstgPcB\nDJcVtCzrUcuyRliWNaJ/f/UTRorPV/ZPC4+zhqcDsaN2WvvBGrZmX6ClJbNvmVXkqN13yK/HznIe\n0q4gN+ag7br57k+F3l3TQeq6wbpua8HLPzoWv/jKME85p8Vq34H+6SncFGKxCjsTMldgytJ7mJrK\ny1NqC5Af5x46SPp9qcVnz4a67Oc4z11SrwtJLjopJSot3cLLAI4TQtQJIboDOBLAHAP1khKyR/+e\nWHz7qNClbsIQij0saNC1g65lQsd9K8lqkVUdZEb/23eOwP0XHZL3wNHhmtOG4dej9sVp++tZxZzt\nPHmfHbHvwN646qQ9PeX8BN/E60ZmPztj1Gx0hNV23eUzGP2QNUk3vcP715ykVd4U/Xp6c4/Fgd8s\n2lLLjV5dHcIqxv2Uu66Ku/17ZCzcJEfYC7mTsoqxEkI8C2AigGFCiGVCiMuFEFcKIa4EAMuy5gB4\nE8AMAB8BeMyyLN/UDKS6yGYl9+n09tcqsUE6b/bOorovMjv27oozDtrZ9/fB23fz/Q0Aunepw3eP\n3z1rxVFttV2uf68GPP7tw33L+bkABvbJtUtmkdMRVjv0zM+HFXbqZdfGsqw8K1xYPrABMc4gDGr/\nHeeFx9uZaYO8EXE/sMOsmnkvGWUufuKEp6b41GlZrGJsiCahr+SWZX1DocxdAO4y0iJSUah604Ie\nLrblw+/hXUze+8WJygJAt21RY7FU6derAVipVvaYPXbAgsYt2b/DRK3s91Qqv60H7aK3HqOMP154\nMK7+xzTt7YIuxYGD+mjV9eZPj9feP+D/YDbiCgw4wP0G9saclZt9f3eK31gtVjHWXQxqhIg1ya4u\nSQrWjougtVfdJOl8cFoBUSJqp82to+dTr8JAZQ9mKjFPdjxW3sPCZ7NrThuGJy/ztwzJ6NlQp5Rm\nwon6c1OtoNqSO97v/njBwb7BoE4r3HmH7oLfnJE/K9Nvj3sPSCc3lZnsU5aVZ6UxoR927BWDVUuz\nXfvspB7X5iTOWKqgu+jrI3bJpl2R4WxWnG1MSozVoUOiCfyENL+q0BFWZeUKJMRJXGNL0KDVmY2x\nCq+nQ2NBvB+euCdOHLajcnlA7+EgEzfnuLOy59Xtvx0A/OvKo3Ht6ft4XIGv/vg43Hy2/1I6Ntv1\n6IKvHbaL9Lc/XHBI9vPu/XugvrYGb/30BFwwQp4F3+ayY3fD4ttHoY9kjcQkpVsIumzFynzu94yI\nW3DU1Agc7Zrkkb9/R9mAtkSZzHHD/0RLmxInPz/VOyGkHEmQ8Sw26nUmtCTohFBYkVgx8QactUJJ\nXYH5f9vLtsh2+/wPji64LVFwPrhP2sdfyIWdqcOHbo8rv7SHZwbeAYP64BLXUjaFnHZ722E79cLl\nmSD4o/eQP5jt8/3IJd4s/E5r5O79e5T0jT9ozC1Wu/z2YyLFQeDxBew7/buaVVG1nc4gbGeMTFIM\nPjpWECC3FmhSLG4AMDJgHKkkvq+RiJkWK1J2RE+3YG8fvddnZwX65EpyYlu3nCXtB8cBmrE0MnSG\nVtkRnzncPyi+lAO3n9Vi7wG9MOHakbj8uN0wqG83T96w5tYOAOl1/A52uZucA929Xz9YyTLkriOo\nnaYo1lkvVfC6qfpV+6efCDfBGQcNLLgO3ZFINYVLMamvFbFFFJXqBVTGrjuoz5RkjBUpXzRHaXsw\nds8y06EzIN2Cm+xCw4523nDmfuhaX4P6msK7u87hX3bsUJx7yCB8T/GtK3d48Q0Qfs0XAWV27tsN\nQgiMv3Ykbjknf2bf1rbO3HauDVNWbqirqxFK5073yGULW8v2E2ixKZKg9bPexu+KDJt44CgZcC4K\ntayZOM33X3QoRuy6XeEVaSA7J4P6Bs8Mjps4vV4HDy7u+TUFLVakfNG8o2trBO782kF4wbUO3tAd\nNBYPDpwVmP93Z8obY3Xxkbti7k2nS5NYxkmvrvW494KDpQ9/GfYDtpBB8+R90y6CU/eLnlle5wHY\n2t7p+5t7BpVStSEH767DmYMpKkWzWPl8H0e3/MYRg7FLJtFt2PV0xrEEFbUT30YnV/slR8lXTEgi\n9vVxnsd/l9iqE6eG0O2OUWfJmiZBIVYUViR+vj5iMAa7FoF+4+oTAKgNEEGzAj0xVp1eV6BJYl1L\nzUDV++/cB4tvH4UDd4nu9tSJi+twvCa6t7JcwetxGIZkbdW9Ru4q3MsEmcLXYKp5Yu6/6BDPd243\nyM9PHZbnwgragzO7dZBRVzc2Kd0w+R1+89kH4p7zpQt0xI7uUcj62E4x5lxTIUlZxsOW1jluz35F\naUeSzgmFFdHD0NOxW5f8lAVBD0OtWYFx24OTFGhhkKhnzZl01O0ycboC40L2rN+uh9ey8uORe+X9\nfd3p+2Q/u/vepa6JADZXn7wXvnpgAZZAn86j26WGbO+19rqfKU4xEObqrM8LMPcvm5zHVnGx+5jO\nOY0by0JiLkiYJ+Co3bcP/N0UCTkdACisSBmQC5uSBa/nY683172LXq6pJJBb+Lr4ON/2dB4anQEW\nK6fGTVdp/mEksybcf9Ghnu8ucgXdf3m/Abk/XFX4Hf7Pvrw3HrzYO/tRFb96TTyj3clX01Yqtdl+\nOsuGAMAvT9sn8Hc/w4G7Dc6/d++X4OVcMg1N0jtV1DHimtPCU03o9sekLAZNixUhGVTuhc6AWYGj\nDhyIUQcOxJ1fSy9L8scLD8EvvjIMlx0bjzsnzjGklG/BThGk4/FxWgh7uuKdenWtcwm2yM1z1JFf\niaz79OvZEPqW7NzO88CP6RHqFIFvXH289HsVBARuP/dAnLJvWhx++5ihngWshci5B8Nqz7NYKTTl\nzIP9Z7YGsX5rW6TtSk0uxire+1NHFqStwfpCwu4zJom6WL0qpx+gZiVm8DopO+Lus0Fjlp3UcgfJ\nYrndutTigYsPxddHDMbi20dhzx174qqT9kQXncRyOu2Mpdb4687uw2cnToGr0w7nZIG7XTEzpzqs\nQiImueK3xIjOy6u7XXE9P531du9Six17NUj3r8KFRwzBMQFpDVStVQCU7xX7nIa113J9fiBjQXxA\nEhtWTpR27mY+Qf17+g2nFrQPXQEZt7BSvZcTZLAKXyuQECfFtKmcOXxnrNvaih+P3BNXfmmP2MRS\nUiilRT0V0RXotFj1c6TUOGBQ77x6LFhK9YbFa9hVdKmtwZkH74wFjVuwZF2zp9xxe/bDpEXrfevJ\nE5KudsV1HfJidCDQs6EOjU2t2vvLBqUHbedMoRBy1zqD0oNKZi1gmu0dddBAjDpolOf7hHiQQsn2\nlZjbq6MLLKi7XOMmdmGleGaStI5jZT+pSOIJuhXu+8YhePq7R0EIkRhRZcId8ME1J+HVHx/nrTub\nbqH4A4Sl4Qp8+apj8YMT9wCQH2PlJKp96r4LD8Flxw4NLXfQLn1w9/nDfR8iV520JyZeNzKghly7\n3ec7LpePZ4akgovpiW+PCK3XsizPMTgfdkLIr0evhjp87/jdsH0PhyU4oC05i1VpFVFniR6gSdKB\nQWOEAHDiMPmaoHF07SjCym/NUhlJcvGpkoynFUk8CXoZKCkmxqXB23eXZoEv7ZIv6har4YP7Yp+d\n0st8+AorSdySyhvl4O2744b/2T+0XK5eOTU1AgP7+CdxDFsCRgfV6+axjGX+DXou7Z1ZTkVaX8C+\nVJ51+w7sjetH7Ze/UHZA+azhpsQKw93numkuiq7C4UOjJ8k8YFC0Rbp1XYHRhuTiTCDJ26Pkd51U\nG6rPHlqsSNlS6kG1ktGZFfjmT4/Hh9edbGzf3hl8wdRlEh75Cyu9juIOvg4jriH0prMP0HfNqZYT\n+Z+DztEu23XDrN9/Rek8ymbe56cG8GuQ96sgQXbD/+yHvt3rsZ1kwW3ftgUK2GiDyR8vPATfOz43\nOeU/Pzo2Uj1BnHGQN0BftU/v0lc9+XFUgtxjxZ4EExpz5+gEtts5rIk79+mKd352gl2DUjsSpKso\nrEjhfP+E3fHHCw8udTOKQqyzAjUyr++zU2/s1MdckkLnQK3ywLPN/355w2Q1BB3Xu784MXSffvUW\nivNBdOlRu2o/8FXH83xXYPBeamsEejTIQ2BzMVb+NbjjuWRFZSKqb4BoOuOgnTHtt6eW3C2/W78e\nuPy43DJRewVY9aLiFANRLXVxxh5JFpjIEhh65/PjvJtPy/tblivNjzqNdB2q6y7u1r9H9rqqCqZd\nNVbziBsKK6JEdsqx5Ja47qv74qyDBxW5RaUh6ZnXo6ITYwUADfXpoaOLT9ZWdx3pY/MfIYPcdjIK\njUNzbt3TJWB08zr96/vRljcJut5BM/DcfVB2KvLX//PZv6T2fpKZt0mmKPeMpbeaw+Dt0335jvMO\n0tuN6++dA16cwgK6fQPbfco31EV3p3YNccXWSRLQ6ljVVF183z1ebU3WYkBhRZT4xVeG4aIjh+Dc\nQ6tDQJWCUnpZ82cFhpc/Ya/++MnIPXHjWfJ4KGkyVwOmelMPUrstew/oCQD44Yl7ZNd03KFnAw6U\nxMD5cdAufbHotq+Glqtxzb4LEun29Qg63hGZOKCRmfUhndTWiGx+qnTwuhdZ3dedvi8uGDHY4CqY\nYQAAGr9JREFUf6cxods1ovSDe84fjse/NSKyq0x1u15d67H49lHZNDFxYFn+LxfFXnA8LMZq8HY5\nS5Kqxcp5byTIw6cM0y0QJfp274JbzznQeL1JyparQjEShJZ6VqCqK/B/T/XP4lxuoXjXnLYPrnFk\nFD/7kEGYuXyT0rZh8VLZcp5t7O+926ZSlu9v9nb779wHn9/6VdTWCIyZ0+gqI9CjS3p4b+uQ+41k\nTd6uRxfc8bWD8NzkL0KOpnAKuZd0Nn3smyOwZksrzssInUkL12ntSzfbQlQPoHuzoD5VyryCbsKO\n11mXbjJcIFmxU6rQYkVKSi5+odwexeYp5RnIi7EqoCHPXXGUbx1+4+OhQ/r6/BIfuazkhZ91u4Zv\nHb0rnrr8SP9yTvccRE5IS86M6pqXQXE89rJOW1s75e1RPPY/Xngwnv6u/3HFyfl+Vh9FywcAnLLf\nAHzjiCHhBX3IumUVu0pRxrKAWYFB11V5okXI786ZjzrHq5SDzfW7fZzfjWlx9DigsCKJgLKqtDFW\nzmDYKG+VNm6h7Hzb9IuVeOGH8lldQgDjr5XnoipUkOs+LIOw2/D7sw7Iuud8Sjq2yf0l01D2bEv3\nTEL3dzYycWYLq+a2joA2hdO/VwOO3bNfpG11ra/Dd8m5YC8+cgjOGB68fE4xREz8S4nLCYzBC5wV\nGK3O/HLBBUcO87qfZdS43NAi+6/6dbP70PF798cz3yuNwNeFwooQDYoxK9DNvV8fjmdithgErZ2n\nQ8on0NdZ58A+XfOytMt44tsj8P4vTsKgvvlB7fasNTuPVhJwu/h8y+VZrBx/S56R7Z0pT921ErFq\nI/vuihPSSVwP3KWPtGGqgqGYCUHv/Fouv9Et5xzom4ajkDYpuW2lZfK/e/mqY3HxkV5LmKkxIqie\nlOW95iYnIapWdeRuwWtyelc1UDM15q3a4JjIUchLXzGhsCJEg2I8ZNyPu3MP3QXHRLQYqKIbvO5L\nphrZAGjvonfXegzoHSysRu4zAIMlU7736N8T/7ry6GwS0bys4TrNDNEUOpYWt4tPbaPcdjKBk80P\n5oxPyTw5/XKHuTl6jx2w+PZR2LGXubQccePuNn6uTtUg6KjkpVvwsW4OH9wXO0heEIIe/sfv5X8f\n79avR97f7r401JFOQGb9PXSI11r6+LfyM/eXImu+zOoKAO/87ATP+qIynEspUVgRQvQowpjhN7A6\nHyRmXIHpf+/7xiE455D/396dh0lR3nkA//76mHsYmINhOIcZxkHuU04F5MYDRYmSVTyXqOCFsqKP\nEoNG0d0cz5psXHfj6j7ZjTFLjMGsrmwOfTSJ0RjjgUpQyaPGKNHEVRMP8N0/unqmurruruqq7v5+\nnmee6amufuudfruqfv2ewzCmrSGw5reZnc19Q7z//uRJuO6ECZ7T6Gqrx5jBDdh23LjCMgP3zVF5\nc0tpZWHaFGhy48xOrljsGaa9lpc+e55H+xn+TrlcO9JoaoD99lTflwWbJ/V5cpGW0Q8vmo8FDs1r\n37tgHnaeP7cvnWxSN588CbsvPQrfPHMm7towO2f6A+O5LALs33GM87JRDmU+vbMZx0zqwA6HKSXy\naq6130op9LQ3orut3viSvNfpl1IKeVnCwDCwIvKgOPPmhJf0FIsbzoCadCDpG4On3iGN+MopU5BK\nJkLpqzKwrgqnzx7l+XU16ST+d/MCzO02r0FYObHDV35smwIN+/XVWJncbQ8eymxrqe+vEck2Bbqt\nsTJz8eIe368tBuP7l53hP28/h3Ts5pCqr/Y3Z5Pb2h4/14jxQ5vyoi5jOs31VaarM4wZ3ICe9kY0\n1aYxu6vFkBnz45kFeNmpR2xe1iedFHz9s9PyatnM6fsWWjdnW9FfU5wWaY8LBlYUrRIbShvmaW12\n0QzasIG12L/jmLztc7pbXM3o7aS/j5V1U2ApjAA19u1yy8uoK5suVn2jApMJQZd280rY1Fg5fWb0\n+cr2W3J7c/NeWt4/wdng0vjZsG4KzGy3Cnbs8jx+aBMuOnqM5zyaMftP7Wp8vXy5sO3lVWCt5biO\n/PUMv7NhDu65YK6r1/sNMo3XOKem3sy+/U2ByRK4dgAMrCgmSuR8CVWUb4GIYNWETC1NIV8Khw/K\nBCTzTfqSHNbeiFmjm3HjmoklOTeNG/rA4NfXLM15Lnf9vv4qK7cVUMmEt/3NKAC3nj498ziGZZDX\nFOg0C77Pz+oxJmsBWsm+TWbnhdl7mLZYjcDtcbKMSy3pt+UMNnGRltHaGfnTWAyqr8JUrZ+W05cf\nL9fr7L5Lx7VjvtZXNBvcW03Eq0++v7uhlEwfK04QSkX1q6uX4ONDNgtdxVwp1Lb4dfGSHux98z0c\n2dPmO42utgb8bOvR6DBZjqMqlcB3fC7/EkcdTTV4490Pc7bpPx1pw4i2vFGB2T9cRjjZG7tZU6CX\nIKna442/kM+87SLMJukat1ndSJ1ylH1ZECtF2A1kMKuBsgsG7d4P43P6VLLrgmY/A0oBUkDdtoig\noTqF9z/yNxWH3fu/a9N8HPe1R7T9ckf3/cPaydi89LC+dTCtPluSW2WlbUOg66OGiTVWVFQtDdWe\n14WLk/INqzI1Srs3L+hb2sWvoQNrHW/GbY32owJLwT0XzMO/nTXT12tz+lhp2y5Z0t//afHY/I7M\n2SDj00KqrHwo0nyXmWMZtlt1XnceFSh4+YZV+JKLUWfm6TsHfUCwNVb5B+x/eI42Oeb4oU1YP2cU\nblk31TZf+i2W76G7Q3s2cXgT5mh9vapTiZy0atJJdLU1mL/QQv9kvqVz3WBgRRQzpbbMjx9fPWVK\nZMeur/K/4KzekKYaLDKM5Mr5om1TjqL7Lp/tM6UPaP/ptGl5r8k2BZqNGHRSrIrW/zrPX42k1YhR\nyz44Lm79iYT4rm0zm27BdD+TbWYLk2dnrvdzarc2VPeN9EsmBNtXT0Bna71tfZX+uc8t6F+cWDm1\nIWafcmqBddjh5pMzgwdqc841f9e1vlGZ2mfBbsqKuGBgRZGKalZjv8K8QWVXmF8bwSK4xTaovgr7\nvrgSz29fUfRj77pwfmhp291wEoa2wP4aqPx9s58Fs9cXMirQz53dy0e+ocZ975KcIfUWSwzZLdkD\n9J+PO8+fY7o9SKYz3pu8nWZNgW6yM6A2973zMhDC7jmrIneTvlmQ6EaVrhncT3Cb28cqd9Lh28+c\niT3bl/vKV7EwsKJI6ecoKQVh9rGqSiXw/PYV2HZs4XMrlYJUMmH4RlscXpsi/MrvjGz+t/7Gcf/F\nR+Knly80TS9pO4+VfcBkOkozgC811/uYQ8xsclirGit9M1aLfjJYw37TRzXjpRtWec6LG/pRafrf\ngHntp11ToP49r0nn7rd68jDcuKZ/oXuna42bGNluFzfXsuxglPzXOh87Ly8ePm4mXaz6tqWTCdRV\nxbt7OAMrioW49wl3nFAvILVVyZKZq4UKYxbsHN4xAJ2GuYHmdGf6q/ztUZkmnbFD8ofKezwwAA/T\nLdh8HE+d6a129edXHo3dmxfkbdfn5YjO5r7mHn2N1fc39q8p2d/Hqv/5ZCLTITuz3ZuNi7od98ke\nS5/2hgVd2LpybM4M4mmzzusmm164bmXO34mE5CwWnX2Jc7Oc/eHMpi5wk66e1USeThS8l0VGbqd3\n47a4i3fYRxQT244dh2uOqYyapHJVlUrgcJP5e8JivA3k3cgMAY5VDcK1x4/HuUd2YXRrveVkqJ5q\nAzzcoGZ2DsKk4dazmBvzbMyHMVv6gSumAYEAd+v6aTXVpjGwLo0vHD/edImjvFpAy5za27J8LL7+\nk5dMnzPWpun/5+pUEuctyARlD+09gF2/+T3qbWpTlMrUVH34Sbgjo4PuYHHZsl5cd9+evlGwjqMy\nAzy2scaqFDCwInJBRErqxKZ8e69f6bxTgBpr0ti6cix23P8CgPyAxth53Uo6mXCc4dptYOX2hiuS\nSfOWddNsm7YSAnz3vDlYe+vPPeXDqK851HCSpZIJPLVtWX7+HNILssneOGLRKuXrV0/AtJEDcYTJ\nwsT6sn/0iqNdTXOQ7VNXyH9S6Mg/q9GaTm9vttZ9UF0aC3rbsO6IkZ5m/c9JX/tslMocVgCbAomI\nQpOtzTAym24hCNetHm/asdfrPSmtLSXjZnTYzM5mrJmamS+q0UPndb3+vpbuiEPQ4ZROnUnfqFaT\nBZUzecsN+qxu8E11aZw1b7RjUNfSUI1RLc5Na8a+XX747WPlXKtp/3xrQzWuP2EC7jz7CKSTCdy4\nZqLlHFROnxmT9chjj4EVEVEEsjev/ht34Wk6dex1u0Bytm+T2yzdsGYivnveHIxorss9hsOUEwCw\nauIQz0GEZbouXz+iuQ63Gqa0uHfTPNN9nQYheOEliHYa2FPo4AO7fyOIgQ2nzR7las7Cx65ajKev\nza2VNB0xWkKRFQMrilQFTNlEBCD/ZtW/CHNx85FdJ+58i9o0QDcaz+XNrCadxMzO/CYwt7yODu7v\nd2O+v5ub8IoJuQttO60P6bYzud/8+H2N3Xtml8TSce3eMqRPN8Agp64qlbcIfO58cNo2m/9mwrDi\n9Z10g32sKBZK6MsIVZDOljrsf/svgaerFFCrTfoIbzGMeXoeahia6tKmC3HrZediKsY0KEr576Bs\nMR4gWIaORl7ek19cuRhVqQT2vvleblpuDuuwr/tFtM3ze90JE3DX46+aPtc+oAZ733zfch6rsD8V\nxqVwAOvPxsNbFqG5ocr8yYiwxoqIyMS+L67Ejy5bGEraA2pS2HHSJGxc1I1Zo1sKTm+GVlvU095o\n+rzXG2FKu6H6WQWgxeVNzrxWwh2nbAUZEGaXUVl4WGaWfS/B35CmGjTXVxXWAd3HdAs5M8frojn9\n+2Y3KOGWdVPx5c9Mdhw0UQxOQffIlrq+aTbigoEVRarUZl6nypFKJhxn/vajt70RIoK2xmpsWT62\nb2HdQtpX1k4fjp9tPRrTRw2y3c/t+ZZtCvzExyzvFy3u8bFskNfICqb7BzUacJrufexoqsEvr1qM\ni7W1HItVs+iYVoiXzoF1VVgzbXjOtuyyOkCwoy6z9LVj+uQ3Lz0MqYSg00WH/7hgYEWxUEodE4mC\nlA1iConhRARDHfoI2dEvQQL0NwUeOuT97l2dSuKUmSOdd9Qo5b2PVTqV2W+yxRxbhV5PJg0fiJtP\nyqx3pwAMHlBjOo+VW4UEIlavzI6mM11CR3e8oGrv7tAtOG6V4hNXL/Gd/iNbF+HSJYflbV86rh37\nbliF+pjVStkpnZwSEXm08/w5+OhguJMxumVVw7B5WS8UgJMMNQTF9KPNC7D/7Q/6/j58yAC8+s5f\n8wKuIOlvzvXVKbz9wceug8u6qhTuuWAuxgzOXZ4oyC9oxv/dqa+PncM7GtFQncIlJoGDlTXThuOm\nB16wDMpu+exU3Pvr36PXovnXTCGVXKNa6jFxWBOeef1dy/fAasoKNwY31qB7cKZWqtS/aDOwokhx\nVGA05o9pxSP7/hh1NgIjApw9b3Te9umj/I9UC4vxptFUm8b21d7X3CvkmEYjmutyZjb/yilT8NSr\nf7ace6jQ4xl965xZeOC5N9Di4cY8daR9s2ehjKM2B9SksH7OKKyd7n2R9MaaNJ79greFg4+d1IGb\nHnjB8vnBjTV9yxwZ+ekb50bYXTdKbe1YKwysKCZK+0QqNd86dxYAoHPrDyPOSTBeudF+lFuhZnfF\nL0Dzw+39tr46hXljWsPNjEZBYWRLHTYc5bxen1tB1HhUpzJ9iuqrk1qaEnoAHLZqQy3c2fNG45F9\nByz3twqkQg98Svx2wMCKiMjGk9cs7bu5lqqgOxsv7G3DT1+0viG7EUZzT5BJLhvXji3Le7F+jvn6\njHFmVt6TRwzM64e37Thv65+G3cJQLg0YDKwoUkcd1oYH97zpe/V0orA11wczR045NXvfdvoM/PWT\nQ477RfU/BxFIJhKCjYvGBJCbwvj5V/RNgdnXLx47OKAchd8HqsQrrBhYUbT+ZtZIrJrYEdjNi4jC\nV5VKBNaxPcjgK4iAythcFpUg3pegayrL6ctBmBhYUaREhEEVVYSutnp0tdZj27Heml+CVCn3Rb/h\nxK5N8zF4gP+RbUH4/HHjsPPJ1/r+LmhtwoAjIb8z5Lu1fHw7Tp05Apct6w3nAEUSj9CciKjM1aST\n+PHlCzG3SJ3Co+Tuvhv83bnQFCcOb0L7AH8jIYNy1rzRuO/CI/v+ThQYxZw4dRiSCcFxk4f6TqN/\nhGS4oXl1KokdJ03qm+2+VLHGioioQlRKU06pz4MEACOaa3Hu/NFYN8v9ZKtGIoKutga8dMOqgvKS\n/dzM7W7FC394Dy31pR34hI01VkREITpmUkfUWYiMm3mPgoz1yiGgyhIRXH3sOHS3NTjvXCRXrRqL\nh7Ys9D2/WaVgYEVEFKKvrZuKV24srMag1LgJcMIMgkp9gslCZefgCnqpy1QygVEltGZfVNgUSESx\n9q/rZ+ClA+9HnQ3X6qqSOG12/9xHYSxY61VUWYhuuoVojhsXN66ZiJ5HGzCvu/z788URAysiirUl\n49qxBO1RZ8O1PdtXRJ0FS2EvSeJHpfT7MrNr03wc/DT4tSzbGqtxxYqxgaVX6YGqVwysiIio6MK8\nV5dKHDBxeFPUWaAQsI8VEREFyk3zZ1qbiDPY5YJKJaSicsYaKyKiMhfHztwLetqwZXkvTptVemvx\nEdlhYEVEVCli1J8pjLX42BeI4oBNgUREZS6yUYHRHJYCUskDCwrBGiuiCvbjyxagoYaXASovbuOB\nR7cejT998HGoeaHKwysqUQXritGszkSF8loxN2xgLYYNrA0lL+Ugzk2rf7eiFw+9eCDqbJhiYEVE\nVCGK1bIT9f2YTVjl74KFY3DBwmD76AWFfayIiMpch7a2W7nXzsS5hoUqB2usiIjK3PGTh2JAbRoL\netqizkpRxHGG+VLEmj9/GFgREZU5EcGi3sFFP26xb8xxnK+LKg+bAomIKFDJRCbASVTY4s9EAGus\niIgoYOcv7Mb7Hx3E+jmdRT0u+1iFhW+sFwysiIgoUI01aWxfPSHqbBBFgk2BRERUVtgSSFFiYEVE\nRGWBDVYUBwysiIiorCj2XqcIMbAiIqKycPKMEQCAptp0xDmhSsbO60REVBYuXdKDjYu6UZ1KRp2V\nsrBleS/eePdDzBvTEnVWSgoDKyIiKgsiwqAqQD3tjdh14fyos1Fy2BRIREREFBAGVkREREQBYVMg\nERER+fbPp0/H06/9OepsxAYDKyIiIvJt+fghWD5+SNTZiA02BRIREREFhIEVERERUUAcAysRuV1E\n3hKRZx32mykiB0Xk5OCyR0RERFQ63NRY3QFghd0OIpIEcBOABwPIExEREVFJcgyslFIPA3jHYbcL\nAewE8FYQmSIiIiIqRQX3sRKRYQBOBPANF/tuEJEnROSJAwcOFHpoIiIiolgJovP6VwFcoZT61GlH\npdRtSqkZSqkZbW1tARyaiIiIKD6CmMdqBoC7RAQAWgGsEpGDSqnvB5A2ERERUckoOLBSSo3OPhaR\nOwDcx6CKiIiIKpFjYCUi3wawEECriLwG4PMA0gCglLo11NwRERERlRDHwEoptc5tYkqpMwvKDRER\nEVEJ48zrRERERAFhYEVEREQUEAZWRERERAFhYEVEREQUEAZWRERERAFhYEVEREQUEAZWRERERAER\npVQ0BxY5AOB3RThUK4A/FuE45B3LJt5YPvHFsok3lk98FVI2o5RSjgsdRxZYFYuIPKGUmhF1Pigf\nyybeWD7xxbKJN5ZPfBWjbNgUSERERBQQBlZEREREAamEwOq2qDNAllg28cbyiS+WTbyxfOIr9LIp\n+z5WRERERMVSCTVWREREREXBwIqIiIgoIGUbWInIChF5UUT2icjWqPNTqURkv4g8IyJPicgT2rZm\nEdktIr/Vfg/StouI/KNWZk+LyLRoc19eROR2EXlLRJ7VbfNcFiJyhrb/b0XkjCj+l3JkUT7Xisjr\n2vnzlIis0j13pVY+L4rIct12XvsCJiIjROQnIrJHRJ4TkYu17Tx/YsCmfKI5f5RSZfcDIAngJQBd\nAKoA/AbAuKjzVYk/APYDaDVsuxnAVu3xVgA3aY9XAbgfgACYDeCxqPNfTj8AjgIwDcCzfssCQDOA\nl7Xfg7THg6L+38rhx6J8rgVwucm+47TrWjWA0dr1LslrX2hl0wFgmva4EcBerQx4/sTgx6Z8Ijl/\nyrXG6ggA+5RSLyulPgZwF4DVEeeJ+q0GcKf2+E4AJ+i2/7vK+AWAgSLSEUUGy5FS6mEA7xg2ey2L\n5QB2K6XeUUr9CcBuACvCz335sygfK6sB3KWU+kgp9QqAfchc93jtC4FS6g2l1JPa4/cAPA9gGHj+\nxIJN+VgJ9fwp18BqGIBXdX+/Bvs3mcKjADwoIr8SkQ3atnal1Bva4z8AaNces9yKz2tZsIyKb5PW\nnHR7tqkJLJ/IiEgngKkAHgPPn9gxlA8QwflTroEVxcd8pdQ0ACsBbBSRo/RPqky9LOf8iAGWRSx9\nA0A3gCkA3gDwpWizU9lEpAHATgCXKKX+T/8cz5/omZRPJOdPuQZWrwMYoft7uLaNikwp9br2+y0A\n9yBT1fpmtolP+/2WtjvLrfi8lgXLqIiUUm8qpQ4ppT4F8C/InD8Ay6foRCSNzE37P5RS39M28/yJ\nCbPyier8KdfA6nEAPSIyWkSqAJwK4AcR56niiEi9iDRmHwNYBuBZZMoiOxrmDAD3ao9/AGC9NqJm\nNoB3ddXsFA6vZfE/AJaJyCCtWn2Zto1CYOhjeCIy5w+QKZ9TRaRaREYD6AHwS/DaFwoREQDfBPC8\nUurLuqd4/sSAVflEdf6k/P0b8aaUOigim5D5wCYB3K6Uei7ibFWidgD3ZD7zSAH4T6XUAyLyOIC7\nReQcAL8D8Blt//9GZjTNPgB/AXBW8bNcvkTk2wAWAmgVkdcAfB7ADngoC6XUOyJyHTIXIADYrpRy\n2+GabFiUz0IRmYJME9N+AJ8DAKXUcyJyN4A9AA4C2KiUOqSlw2tf8OYBOB3AMyLylLbtKvD8iQur\n8lkXxfnDJW2IiIiIAlKuTYFERERERcfAioiIiCggDKyIiIiIAsLAioiIiCggDKyIiIiIAsLAioiI\niCggDKyIiIiIAvL/ATBdKAAr6EUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83191c7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N1 = len(solver.loss_history)\n",
    "x1 = range(N1)\n",
    "plt.plot(x1, solver.loss_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAHVCAYAAADLiU4DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xt83FWd//HXyeTW3No096b3NqV3Wigt4g3kIoJSUEBu\nigqLrLLiov50d1ldUXfV3WXdC7uKynoBrFwEq4AVRFgQWxpom94omfSSNk0yaW7N5DKTmTm/P76T\nZpKmbdrMNXk/H495ZOY735n5hIbm3XM+33OMtRYRERERia20RBcgIiIiMhEodImIiIjEgUKXiIiI\nSBwodImIiIjEgUKXiIiISBwodImIiIjEgUKXiIiISBwodImIiIjEgUKXiIiISBykJ7qA4YqLi+3s\n2bMTXYaIiIjIKb3xxhtHrLUlozk36ULX7Nmzqa6uTnQZIiIiIqdkjDkw2nM1vSgiIiISBwpdIiIi\nInGg0CUiIiISBwpdIiIiInGg0CUiIiISBwpdIiIiInGg0CUiIiISBwpdIiIiInGg0CUiIiISBwpd\nIiIiInGg0CUiIiISBwpdIiIiInEwqtBljLncGLPHGOM2xnzlJOd9xBhjjTGrwo9nG2N6jTFbw7fv\nR6twERERkVSSfqoTjDEu4AHgUuAQsNkYs95au2vYefnA3cCmYW9RZ61dEaV6RURERFLSaEa6VgNu\na+1ea60fWAesHeG8bwDfAfqiWJ+IiIjIuDCa0FUJHIx4fCh87BhjzDnADGvtMyO8fo4xZosx5mVj\nzLtH+gBjzB3GmGpjTHVLS8toaxcRERFJGWNupDfGpAH3A18Y4elGYKa1diVwD/CoMaZg+EnW2get\ntaustatKSkrGWpKIiIicqYA/0RWMW6fs6QIagBkRj6eHjw3IB5YCLxljAMqB9caYq6y11YAPwFr7\nhjGmDlgAVEehdhEREYmWI7Xw/Fdhz7OQPQUKZ8GUWYNfB+5PngGZOYmuNiWNJnRtBqqMMXNwwtYN\nwE0DT1prO4HigcfGmJeAL1prq40xJUCbtTZojJkLVAF7o1i/iIiIjEVPG7z8Hdj8I0ifBO+4C/p7\noeMAeHbD2xsg6Bv6mtzSiDA2c2hAK5gO6ZmJ+V6S3ClDl7U2YIy5C9gAuICHrLU7jTH3AdXW2vUn\nefl7gPuMMf1ACLjTWtsWjcJFRERkDAJ+2PxDJ3D5uuDcT8CFfwt5w9p8QiHo9kD7ASeIdRwYvN9Q\nDbuehlBg8HyTBvnTwkFs5rDRsplQMA3SXHH9VpOFsdYmuoYhVq1aZaurNfsoIiISE9bC7t84U4nt\n+2D+JXDZN6F00Zm9XzAAXYfDQax+aCjrqIejh4GIrJGWAZOnDxshmz0Y0PJKwWlXSgnGmDestatG\nc+5ophdFRERkPGh4Ezb8HdS/BiWL4JYnndA1Fq70cGCaOfLzAR90HhoaxgYC2p7noHvYqgXp2SOP\nkA3cn1SYUqEskkKXiIjIeNfZAH+4D2rWQW4JfPB7sPJjTmCKtfQsKJrn3Ebi74aOg8NGyML3D70O\nfZ1Dz8/MH9bkP3Po/az82H9PZ0ihS0REZLzyeeFP/w6v/SfYELzrHnjXX0P2cas3JU5mLpQudG4j\n6e0YNm0Zvt+2F/b+Efp7hp4/aepgKCtbAu/9f7H/HkZJoUtERGS8CQVh66Pw4jfA2wxLr4VLvnbi\nKcBkNmmKc6tYfvxz1kJPaziM7XcC2cBoWdN2p59MoUtERERiYu9LsOFeaN4O01fDRx+BGecluqrY\nMAZyi53b9HOPfz7JLhZU6BKR8cvfA28/BzWPwYE/O9MXM9bAzPOdr7nFp34PkVTR8jY8//fw9u+c\nEa1r/xeWXJOyTedRkWTfu0KXiIwvoSDsexlqHofd68HvddYMWvwhZ8XtTd+H1/7DObdoPsw4H2as\ndoJY8YKk+0ta5JS6W+Hlb8PmHzv9UZd8HdbcCRnZia5MhlHoEpHUZy00boPtj8P2J8DbBFkFzr/y\nl38UZr0T0sJbzfb3QeNWqN8IBzc5I2FbH3aem1TojIANjIZNWwkZkxL3fYmcTMAHrz8IL/8z+Lvg\n3E/ChX9z/OKmkjQUukQkdbXvd4JWzeNwZI+z6OKC98Py66Hq/SP/Sz8j2wlUM893HlsLrXVwcGNE\nEPud81xaBlScPTgdOfN8Z+FGkUSy1hnFff6rzv8D8y+Fy75x5oubStxoRXoRSS09bbDzKSds1f/Z\nOTbzAidoLV4LOVOj8xkHNw2GsIY3B/eeK5wzNIQVnzU4iiYSaw1vhBc3/TOULnZWkp9/caKrmtBO\nZ0V6hS4RSX79vc7oU81jUPs8hPqhZKETtJZdF/vL4AN+Z/oycjRsYBXt7MnOFWIz1zj9YZXnQmZO\nbOuRiafzUHhx0186i5u+715YcUt8FjeVk1LoEpHUFwrC/lcGG+J9RyG/ApZ+xOnTKl+WuKZ3a52F\nGY+Nhr0OLbud59LSoXx5eDRstRPECioSU6ekPl8XvPo9+PN/OT93F9wF7/x8ci1uOsEpdIlIarLW\nWdBw+2NOQ3xXo7Plx+K1sPw6mP1uSHMlusqR9bbDwc3h0bBNzjRQoNd5bspMJ3wNjIaVLkre70OS\nQygIWx6GF78J3R5nRPfir6bm4qbjnDa8FpHU0lE/2BDfstsZLaq6DJb9I5z1gdS4gnBSISy4zLkB\nBPuhsWZwSnLfy06YBOfKyunnhfvC1kDlKsjKS1ztklzq/gi/vxeadzg/Izf+AqaP6ne6JDmNdIlI\nYvS2w86nnbB14E/OsRnnO31aS66JTkN8MrHW2ZqkftPgaJhnF2DBuKB86dDRsMmVia5Y4q1lD/z+\n76F2g7Nv4KVfh8VXj3kavT8YoqOnn44eP23dftp7/LT39Dv3u537zjHncW9/kOK8LMoKssO3rGNf\nS/OdY0W5maSlaU070PSiiCSr/j7nF0rNY1D7ewj6nQVJBxriC2cnusL46u2AQ9VOCDu4ybk/sHlv\nwfTBADZzDZQuUdP0eNV9BF76NlQ/5Cxu+p4vwupPj7jkSX8wRHuPn46RQlO3n7aeocfauv109QVO\n+NGTMlxMzc1kSk4GU3MzKczJJDsjjSNeP81H+2g+6qO123fcbjrpaYbS/CxKh4SybErzsyifHA5r\n+dkUTErHjPMFhxW6RCR5hELOSFbNL2HXevB1Ql6ZswHv8uuddbBi/JdyR4+fN+vbyclMpzAnk8Lc\nDApzMslwJdlSD8GAs19e5GhY12Hnucw8Z4ppxvlQthjSs8GV6dzSs8CVAa7w1/SsYfcz1UOWhPx9\nvfhe+x9yNv4baf3d1M/5KJtn30FTIM8JTQMhKny/vdtPl+/EASon0zXk57swJ/NYkBo4dnzAOvXP\nRX8wxBGvj6ZOJ4R5uvqOBTLnq3O/s7f/uNdmpacNjpIVZFMeEdKcUTPnfm5W6v6DQqFLRBKveacT\ntLY/AUcbnNCw6ENO0Jrz3piHgPZuP7/f1cQz25t4zX2EQOj4v+vys9IpzM10bjkZTM3JZEpOJlNz\nM8LHIn9xZTAlJ5PM9DgGNWuh82A4hIWDWPNOsKHTfy/jCge0cFAbEsoGAtvA88MC20nDXeRzkeeO\n9DkjPJ+RMy62XvIFgnREjC6NNBLlHPfT1u3jvJ5X+bz9OTPTWvhDcCX/GLiJOjs4pZyb6Qr/LA7+\nfA7+PB7/8zklJ2NUASqW+vqDeI76aA6HsqbOPjxdg8HMc9RH09E+evzB416bn5VOaeSIWUEWZeGp\nzPLJzrRmaUEWWenJ948HhS4RSYzOQ07IqnkMPDudhvj5lzhTh2ddEfP1q9q6/fx+ZxPPbG/ktbpW\ngiHLjKmTuGJZBRedVUooZIdMv0T2t7R3D/a0dI/wS2FAXlY6hbmRAW3gl1/EL8LcwZGEKTkZ0f1F\n0XfU6Q0L+J3p2aDPadoP+MKPw7fIxyOe2x9+PPD8id4n4rUD90PHj2icsYwc54q8KbOgcNaw+7Ng\n0pTofVaEUMjS7Q/Q7Qvi9QXoDt+84ZtzP3jsWLcvQLd/8Fi3L0BXXyD8HgH6gyf+XZqb6aIw1/lZ\nOce1l48f/QFze3dwJGc+Wxd/ib6Z72FqTuaxn59kCFCx5PUFnEB2tC8c0HxDQtnAfX/w+H9cFOZk\nhENZNmXhqcyB+wOBrTgvk/Q4jmIrdIlI/PR2OOto1TwG+18FrLNY6EBDfG5xTD++rdvPhp1NPBsR\ntGZOzeGKZRV8cHkFS6YVnHZPycCoReRIRVuPn44T9Mx09PTjPcm0T15W+rEpnSk5mUwdEtAynV+4\nw0JbMv6L/phQyAleI4a3YQFtSAgcIeh5W5wQ2X7A+eo7OvSzsiZD4UzslFkEC2bgy5tBd850urIr\n6MiaxtFgZkRIckKUE45GClKDAWuk0ZaRGAN5menkZqWTm+UiL2vgfjp54Ztz38XknPCf5bCpvKx0\nF3QchD983blwJLfUWdx05S2a9j0Bay0dPf2DoawzPI0ZfuwJT2m2eH0Eh41iGwPFeVmUF2SzsDyf\nf77u7JjWqiUjRCS2Aj6nEb7mMXh7g/PLs2g+XPS3sOxamDo3ph/f6vWxYWczz25v5M97naA1qyiH\nO94zlyuXnVnQipSV7qKswEVZwQh7N56ALxCkMxzOTjS9NDCStu+Il47u/pP255xseikvO53knJDL\nCN9yR3W2BXzZQboLA3TnBPEWB7A97UzqOUR+bwNT/I0U9zdR0tRExeEtTDe/J9f4yQUGdsA8Ygs4\nZEs4ZEtotyU021Ka00ppy6igK7uCzKxJ5GWlU5KXxeyi9GGhyXUsPOWGg1V+9tCANSnDNbZGcF8X\nvPxv8OcHnMfv/iK86/OQlX/m7zkBGGOOTf0vLD/xecGQpdXrG+wviwxpXX0jjpYlkka6RGR0QiFn\nv7eaX8Kup6Gv09mOZOm1zsKl086JaW9Oq9fH78IjWhv3thEMWWYXOSNaV0QhaCWCPxCiI+Ly/Y6e\nYSNp4SnPtoj7J7sSLVW50gy5mcePIuVGhqKsdPIyXRSbo5QEm5naf5jJfYfJ7z3MpJ4GsrwHcR09\nhBky9WmcXQymzBycroy8X1AZuytCQ0HY8vPw4qYtsOz68OKmM2LzeZIwGukSkejx7B5siO88CBm5\nsOiD4Yb4C2O6jMERr4/f7RgIWq2ELMwpzuXO987limUVLK5IvaAVKTM9jdJwf8po+QMhekc5NZYK\nsjLSyEpPi86fYygIXU1Dpys76p37B15zpvYiL0IwLmc9tMgessjesrzyM9vMvO5F2HCv09c443y4\n8Zcw/dyxf3+S8hS6RGRknrfg159xtrMxLpj3Prj4a7DwCmctoRhp6QqPaNU0smmfE7TmFufymQvn\nc8WyChZV5Kd00BqrzPS0+F5BmUrSwiFqciXMuuD454P9zsUex0JZ/eD92hfA2zT0fFeWMzI1vLl/\n4H5O0dDRXc9b8PzfO1PvhbPh+p/BoqvGxdWZEh0KXSIylLXOnm/PfsnZmuby7zibTOeVxOwjPV19\nbNjhXHX4+r42J2iV5PLZi5ygtbB8YgctiRJXBkyd49xG0t/rNLx3HDh+tOzwVuhtG3p+Ru7gdGV6\nNuz+jbM0ymXfhNV3OMtkiERQ6BKRQb4u+O09zh6Bc94DH/4h5J+ki3UMIoPWpn1tWAvzSnK566L5\nXLG8grPKFLQkzjImQckC5zYSX9fgdOXw0TJvM6z6FFz4N5BbFN+6JWUodImIo3EbPP5JaN8HF90L\n774n6peze7r6+N2OJp6paeT1/U7Qml+ax1+9r4orl1WwoCxPQUuSV1Y+lC1xbiJnQKFLZKKzFjb/\nCDb8rdOjcutvYfY7o/b2nqN9PBce0docDlpVpXl87n1VXLm8ggVlunReRCYGhS6Riay3A9bf5fSi\nVF0GV38/KlMjzUf7eG57I89ub2LzAQUtERFQ6BKZuA5uhic+5WyofNk34fzPntnl8WFNnX08t6OR\nZ7c3Un2gHWthQVked1/sTB1WKWiJyASn0CUy0YRC8Of/crYkKZgGn9oA00e1rt9xmjr7eHb7YNAC\nOKssn89fvIArl5czv1RBS0RkgEKXyETSfQSeuhPcz8OiD8FV/3XaGwo3dvby7HZnwdI3wkFrYXk+\n91y6gCuWVTC/NC8WlYuIpDyFLpGJYv+r8OTt0NMKV/wLnHf7qBdtPNzRe2xE6836DsAJWl+4dAFX\nLK9gXomClojIqSh0iYx3oSD837/Ay9+Gwjlw+2NQsfyUL+vo8fOrNxv4bc3hY0FrUUUBX7zMGdGa\nq6AlInJaFLpExrOuJmd0a/8rzoa7H7zfWWvoBKy1bDnYwcMbD/Dbmkb8gRCLKwr40vvP4oplFcwp\njt32PyIi451Cl8h45X4BfvVp8HfD2gdgxc0nnE7s9gV4emsDj2ysZ1fjUXIzXVy/ajo3r5nFooqC\nOBcuIjI+KXRJwllr+dEr+3huRyMXnlXK1SsqmVmUk+iyUlewH/74LXj136B0MVz7v1C6cMRT32o6\nyiMb63lqSwNeX4BFFQV865qlrF1RSV6W/noQEYkm/a0qCeULBPnbX+3gyTcPMbsoh/uff5v7n3+b\nc2ZO4ZqVlVy5fBpTczMTXWbq6DgIT94GBzfBObfC5d+GzKEBtq8/yHM7GnlkYz3VB9rJTE/jg8sr\nuHnNLM6ZOUXb8IiIxIix1ia6hiFWrVplq6urE12GxEFbt587f/4Gr+9v4/OXVHH3xVUc7uxj/dbD\nPL2lgT3NXaSnGd67oISrV1ZyyaIyJmVGdy/AceWtZ+DpzziN8x/6Hiy7dsjTB1q7eXRTPY9VH6S9\np5/ZRTncvGYW1547nUIFWxGRM2KMecNaO6rFDhW6JCHcni4+9ZNqmo728c/XLmftisrjztndeJSn\ntzTw662HaTraR26mi8uXVnDNykreMa8IV5pGZAAI+OD5r8Gm/4GKs53pxKJ5zlPBEH94y8PDGw/w\nSu0RXGmGyxaXcfOaWVwwr4g0/TcUERkThS5Jaq/UtvCZR94kKz2NBz++inNmFp70/GDIsmlfK09v\naeC57U10+QKU5mdx1dnTuHplJUumFUzcKbHWOnjik9C4DdbcCZfeB+lZNHX2sW5zPeteP0jT0T7K\nC7K5cfVMblg9g7KC7ERXLSIybih0SdJ6eOMBvrZ+J/NL8vjxJ1YxvfD0Gub7+oO8+JaHp7c08Mc9\nHvqDlvmleVy9YhprV1QyY+oEasDf8SSsv9vZL3HtfxM660r+VHeERzbW8/zuZoIhy3sWlHDLmpm8\nb2Ep6a4z31dRRERGptAlSScQDPHNZ3bzk9f2876FpfzHjSvHfHVcR4+fZ7c38fSWBl7f3wbAebML\nWbuikiuXVYzfPqX+XvjdV+CNn8D01XRe8X0ecxse2XSA/a09TM3N5LpV07lp9UxmFWldLRGRWFLo\nkqTS1dfPX/1iCy/taeG2d83hb69YFPV+rINtPazf5jTg13q8ZLgM711QyjUrK7l4USnZGeOkAb9l\nDzz+CfDsonHZX/Kv/deyfkcL/kCI82YXcvOaWXxgWTlZ6ePk+xURSXIKXZI0Drb1cPtPq3G3eLlv\n7RJuXjMrpp9nrWVXuAF//bbDNB/1kZ+VzuVLy7lmZSVr5qZoA761sPVR7LNfxGey+EbG3TzSuoC8\nrHQ+fE4lN62ZycJyLWIqIhJvCl2SFN440M4dP6vGHwzxPzefy7uqiuP6+cGQZePeVp7a0sDvdjTh\n9QUoK8hi7YpK1q6YxuKKFGnA93npeOJzTKl9kk12CX/l+wzFFbO45fxZrF0xjVwtYioikjAKXZJw\nv97awJeeqKFicjY/vvU85pcmdnPkvv4gL+xu5ukth3lpj4dAyLKgLO9YADvdhv546OsP8qdXX2Th\nq3dTHjjMA6FrqV/6GW5+xxxWzNAipiIiyUChSxImFLJ874W3+Y8X3ayeM5Uf3HJu0jW0t3f7eWZ7\nI09vaaD6QDsAq+dM5epwA/7knIyE1rf/SDePbjoA1T/mC6Gf0pWWx6aV3+Wdl1zNlJzk+m8pIjLR\nKXRJQvT1B/nC49t4pqaR686dzreuWUZmenIvU3CwrYdfb23gqS0N1LV0k+lK46KFJVy9opKLFsav\nAT8QDPHCbg+PbDrAttoDfDfzh1ye9jrt097DlJsewuSVxKUOERE5PQpdEneerj7+4mdvUHOogy9f\nvpBPv2duSk1/WWvZ0XCUp7c6DfgtXT7ys9O5YmkFV6+sZM2cqTFZvb2ps49fvF7Pus31NB/1cXH+\nQe5P+3cK+j2Yi78K7/grZx0uERFJSgpdEle7Dh/l9p9upr2nn+/dsIL3Lyk//Tdp3AZbH4WyJTBt\nJZQsAldiGsSDIctrdUd4aksDG3Y00e0PUjE5m6tWTOOalZVjvkowFLK86j7CwxsP8Ie3PISs5cKq\nIv6m8EWqtv8rJr8Crn0IZqyO0nckIiKxotAlcfPCrmY+t24LBdkZ/OjWVSytnHz6b3L0MDx4IXib\nB4+lZ0P5cieAVZ7jfC2aD2nxXX+q1x/k+d3N/HpLAy+/3UIgZFlYns/VKyu56uxpTJsyadTv1dbt\n5/Hqgzz6ej0HWnsoys3kulUzuGVZLtNf/gLUboCFH4S1/wWTTr41koiIJAeFLok5ay0/fnUf33p2\nN0unTeZHt646sz39+nvhf6+AI2/Dbb93wtbhLdDwpvO1cRv0dzvnZuZBxQqYtmIwjBXOgThNY7Z6\nfcca8N+s78AYWDNnKtesrOTypRVMnnR8A761ljcOtPPwxgM8u70JfzDE6tlTufn8mVy+tJyshk3w\nxG3QcwQu+xas/ou4fT8iIjJ2Cl0SU/3BEF/99Q5+8fpBPrC0nPuvX8GkzDMYgbIWnvo01PwSbngU\nFl55/DmhoBPIDm8ZDGNN2yHoc57PnuwEsGnh0bBpK2Hy9JgHlwOt3fx6q7MC/t4j3WSmp3HxwlLW\nrqjkooUl+AMhnt7SwCOb6nmrqYv88CKmN58/iwVl+c739cr98NI/QuFsuPZ/nTApIiIpRaFLYqaj\nx89nHnmT1+pa+exF8/jCpWedeYP5a/8Jv78XLroX3vul0b8u2A+e3XD4zcEw1rwTQgHn+dySwQA2\nEMbyy86sxlOw1rK9oZOntjTwm22HOeL1U5CdTjBk6fYHWVpZwC1rZvGhsyMWMe1qhl/9Bex7GZZe\nCx/6HmTlx6Q+ERGJLYUuiYl9R7q57SebOdjew7c/vJyPnDv9zN/M/QI8ch0s+hBc99Oxj0z19znB\nKzKItbwFNuQ8nz8t3Bu2YjCM5Uwd22cOEwiG+FNdK+u3HibDZbhh9UzOnj556FWcdS/Cr+4Anxeu\n+C6s/JimE0VEUljUQ5cx5nLg3wEX8CNr7bdPcN5HgCeA86y11eFjfwPcBgSBz1lrN5zssxS6ktOf\n61q58+E3cKUZfvCxczlv9hgCyxE3/PB9MGUm3LYBMnOjV2gkfzc01gyGsMNvQqt78PkpswZHxCrP\ngYqznenKWAgGnKnEV+6HkrPgup9A6aLYfJaIiMTN6YSuU16Tb4xxAQ8AlwKHgM3GmPXW2l3DzssH\n7gY2RRxbDNwALAGmAS8YYxZYa4Oj/WYk8da9Xs+9T+9gdnEuD916HjOLxrBlTl8nrLvRWQ7ixkdj\nF7jAee9Z73BukZ9/eOvQILbr6cHni+YP7Q+rWD72GjsPOc3yBzc6I1sf+C5kJt+2QyIiElujWQhp\nNeC21u4FMMasA9YCu4ad9w3gO0Bkc85aYJ211gfsM8a4w+/357EWLrEXDFm+87u3ePD/9vLuqmIe\nuPkcCrLHsEVOKAhP/gW07YWP/9oZ6Yq37Mkw973ObUB3KzRugYZwENv/Kmx/zHnOpEHJwqE9YmVL\nIGOUV2rueQ6e/kunD+3DP4Ll10X/exIRkZQwmtBVCRyMeHwIWBN5gjHmHGCGtfYZY8yXhr1247DX\nVg7/AGPMHcAdADNnJuAXsRyn2xfg7nVbeWF3Mx9/xyy++sHFpLvGuDL6i99w1qK68l9h9ruiU2g0\n5BbB/Euc24CupqFXTL79O9j6iPNcWgaULR4axEoXgSsikAb88MI/wMYHoHyZ07dWNC+u35aIiCSX\nMS/5bYxJA+4HPnGm72GtfRB4EJyerrHWJGNzuKOX235azZ6mo3z9qiXcesHssb/p9ifg1X+Dcz8J\n590+9veLtfxyOOsDzg2c5S06Dw1t1N/5FLzxE+d5V5YTrgamJKsfcs5ZfQdc+o3Rj4yJiMi4NZrQ\n1QDMiHg8PXxsQD6wFHgpfJVWObDeGHPVKF4rSWbbwQ5u/1k1vf4gD33iPC48q3Tsb3p4C/z6szDz\nAqefKRUZA1NmOLfFa51j1jpTpcf6w7Y4Wxlt/qEzjXn9z2HxVYmtW0REksZoQtdmoMoYMwcnMN0A\n3DTwpLW2EygeeGyMeQn4orW22hjTCzxqjLkfp5G+Cng9euVLNP225jBfeGwbJflZPHL7GmcRz7Hy\nemDdzc7aWdf/DNIzx/6eycIYZ8qwaB4su9Y5Fgo6V0jmlkR9SQoREUltpwxd1tqAMeYuYAPOkhEP\nWWt3GmPuA6qttetP8tqdxpjHcJruA8BndeVi8rHW8l8vuvnX59/m3FmFPPixcynKyxr7Gwd88MuP\nQU+bs8VPXsnY3zPZpbmcJSFERESG0eKoE1xff5CvPFnD01sPc83KSv7pw8vIzojCptLWwm8+B2/+\nzNniZumHx/6eIiIiSSaq63TJ+HXE6+PTP3+DNw6088XLFvDZi+YPXT19LDb/yAlc7/6CApeIiAgK\nXRPW281dfOonm2np8vHATedw5fKK6L35vv+D574MCz7g7KsoIiIiCl0T0Ut7PNz16BYmZbp47NPv\n4OwZU6L35u374bFbobgKPvwgpI1xbS8REZFxQqFrgvnJn/Zx3293sbC8gB/duoppUyZF7819XvjF\nTWCDcMOjkF0QvfcWERFJcQpdE0QgGOLrv9nFzzce4JJFZfz7DSvIzYriH38oBE/fCS274eYntPq6\niIjIMApdE0Bnbz93Pfomr9Qe4dPvmcv/u3whrrQoNcwP+L/vwu7fwPv/EeZfHN33FhERGQcUusa5\n+tYePvUTOWI6AAAgAElEQVTTzew/0s13PrKMj54Xg70td62Hl/4Jzr4Jzv9M9N9fRERkHFDoGsde\n39fGp39eTcjCz29bwzvmFUX/Q5p3wlN3QuUq+OC/Oau0i4iIyHEUusapJ984xFd+VcOMwhx+/Inz\nmFOcG/0P6W6FX9wIWfnw0Ye1qbOIiMhJKHSNM6GQ5V9+v4f/fqmOC+YV8T83n8vknIzof1CwHx6/\nFbqa4JPPQUEU1/kSEREZhxS6xpFef5C//uVWfreziRtXz+C+tUvJcMVonawNfwf7X4Grvw/Tz43N\nZ4iIiIwjCl3jRPPRPm7/aTU7Dndy75WLuO1dc6K3pc9wb/4MXv8BvOMuWHFjbD5DRERknFHoGgd2\nNHRy+0+rOdrXzw8/topLFpfF7sPqN8Jv74F574NLvh67zxERERlnFLpS3IadTXx+3VYKczJ44s4L\nWDwthqvAdx6CX94CU2bAtQ+BSz8+IiIio6XfmimsrsXLnQ+/wfLpU/jhx8+lND+GVw/6e2DdTdDf\nB594BiYVxu6zRERExiGFrhRWc6gDa+Ffrl0e28BlLaz/K2isgRvXQclZsfssERGRcSpGl7ZJPNQ2\ne0lPM8wqisEaXJH+9D3Y8QRc/Pdw1uWx/SwREZFxSqErhbk9XmYX55KZHsM/xrc3wAtfhyUfhnfd\nE7vPERERGecUulKY2+Nlfkle7D6g5W148nYoXwZrH9AWPyIiImOg0JWifIEg+1u7qSqLUejq7YB1\nN0J6FtzwKGTmxOZzREREJgg10qeo/Ud6CFmYXxqD0BUKwpO3QfsBuPU3zhIRIiIiMiYKXSmq1tMF\nxCh0vfAP4H4BPvg9mPWO6L+/iIjIBKTpxRTl9ngxBuZFu6dr2y/htf+A826HVZ+M7nuLiIhMYApd\nKarW42VGYQ7ZGa7ovWnDG856XLPeBZd/O3rvKyIiIgpdqarO46UqmlOLXU2w7mbIK4PrfwqujOi9\nt4iIiCh0paJAMMTelu7o9XMFfM6ein2dcOOjkFscnfcVERGRY9RIn4Lq23rwB0PRCV3Wwm/vgUOb\n4fqfOWtyiYiISNRppCsFuT1eIEpXLm76Pmx9GN77ZVi8duzvJyIiIiNS6EpBtdEKXXV/hA1/Bws/\nCO/9ShQqExERkRNR6EpBdR4v5QXZ5GePodm9bS88/gkoXgDXfB/S9KMgIiISS/pNm4JqPd6xbf/j\n64Jf3OTspXjjLyArP3rFiYiIyIgUulJMKGSpa/Ge+dRiKAS/+jQceRuu+wlMnRPV+kRERGRkunox\nxRzu7KXHHzzz0PXSP8GeZ+Dy78DcC6NZmoiIiJyERrpSzEATfVXpGUwJ7nwK/u+7sPIWWPPpKFcm\nIiIiJ6PQlWLqzvTKxcYaePozMH01XHm/088lIiIicaPQlWJqm70U5WYyNTdz9C/qPuJs8ZM9BT76\nMKRnxa5AERERGZF6ulKMu8XLvNMZ5Qr2w2Mfh24PfPI5yC+LXXEiIiJyQhrpSiHWWmqbu05vo+vn\nvgwH/gRX/SdUnhO74kREROSkFLpSSIvXx9G+wOhDV/VDUP1juOBzsPz62BYnIiIiJ6XQlULczQNN\n9KO4cnH/n+DZL8H8S+GSf4hpXSIiInJqCl0p5NhyEadajb6j3unjKpwDH/kRpLniUJ2IiIicjEJX\nCnF7vORnpVOaf5KrD/3dsO4mCPqdLX4mTYlfgSIiInJCunoxhdR6uphfloc50Rpb1jprcTXtgJse\ng+Kq+BYoIiIiJ6SRrhTi9nQzv+QkU4uv/Cvsetrp4VpwWbzKEhERkVFQ6EoRHT1+jnh9J+7n2vMc\nvPhNWHYdvPPu+BYnIiIip6TQlSLcJ9tz0fMWPPkXUHG2sx6XtvgRERFJOgpdKaL2RHsu9rTBL26A\njElww6POVxEREUk6aqRPEbXNXrIz0qicEhGqQkF44lPQeQg+8QxMrkxcgSIiInJSCl0pwt3iZV5J\nHmlpEVOHB16DvX+EK/4FZq5JXHEiIiJySppeTBHukfZcbNzqfF1yTfwLEhERkdOi0JUCvL4Ahzv7\nju/natwGBZWQW5yYwkRERGTUFLpSQJ3nBHsuNtZA+fIEVCQiIiKnS6ErBbhH2nPR3w1H3naWiRAR\nEZGkp9CVAmo9XjJchllTcwYPNu8ErEKXiIhIilDoSgFuTxdzinNJd0X8cTVuc75WaHpRREQkFYwq\ndBljLjfG7DHGuI0xXxnh+TuNMduNMVuNMa8aYxaHj882xvSGj281xnw/2t/AROD2eEdoot8KOUVO\nI72IiIgkvVOu02WMcQEPAJcCh4DNxpj11tpdEac9aq39fvj8q4D7gcvDz9VZa1dEt+yJo68/SH1b\nD1etGBauBproteWPiIhIShjNSNdqwG2t3Wut9QPrgLWRJ1hrj0Y8zAVs9Eqc2PYd6SZkh23/E/CD\nZ7f6uURERFLIaEJXJXAw4vGh8LEhjDGfNcbUAd8FPhfx1BxjzBZjzMvGmHePqdoJqPbYRtcRoatl\nN4T6FbpERERSSNQa6a21D1hr5wFfBu4NH24EZlprVwL3AI8aYwqGv9YYc4cxptoYU93S0hKtksYF\nt8dLmoE5xbmDB4810St0iYiIpIrRhK4GYEbE4+nhYyeyDrgawFrrs9a2hu+/AdQBC4a/wFr7oLV2\nlbV2VUlJyWhrnxDcni5mTs0hO8M1eLBxG2TmQ+GcxBUmIiIip2U0oWszUGWMmWOMyQRuANZHnmCM\nqYp4eCVQGz5eEm7ExxgzF6gC9kaj8Imittl7gpXol0GaVvwQERFJFaf8rW2tDQB3ARuA3cBj1tqd\nxpj7wlcqAtxljNlpjNmKM414a/j4e4Ca8PEngDuttW1R/y7Gqf5giP2t3UOb6ENBaN6hqUUREZEU\nc8olIwCstc8Czw479tWI+3ef4HVPAk+OpcCJ7EBrD/1BO7SJvtUN/T0KXSIiIilG81NJzH1so+uI\n0KWV6EVERFKSQlcSc3u6AJg3PHSlZ0PxWQmqSkRERM6EQlcSc3u8VE6ZRF5WxCxw4zYoXQyuUc0M\ni4iISJJQ6EpitR7v0FEua6GpRv1cIiIiKUihK0mFQpa6Fu/QJvqOA9DXqdAlIiKSghS6klRDRy99\n/SE10YuIiIwTCl1JqjbcRF81PHQZF5QuSVBVIiIicqYUupLUyMtF1EDJQsjITlBVIiIicqYUupJU\nbbOX4rwspuRkDh5s3KZ+LhERkRSl0JWk3MOb6LuaoNuj0CUiIpKiFLqSkLUWd7NXTfQiIiLjiEJX\nEmo+6qPLF6CqbITQVb4sMUWJiIjImCh0JaFjTfQlw0LX1HmQlZ+gqkRERGQsFLqS0MByEfPLhl25\nqH4uERGRlKXQlYTcHi8F2emU5GU5B3raoLNeoUtERCSFKXQloVqPl6qyfIwxzoGmGuermuhFRERS\nlkJXEqrzeI9fiR6gXCNdIiIiqUqhK8m0en20dvuPX4m+YDrkFiWuMBERERkTha4kM/L2P1qJXkRE\nJNUpdCUZd8uw0OXzQqtboUtERCTFKXQlmdpmLzmZLqZNnuQcaN4BWDXRi4iIpDiFriRT1+JlXkke\naWnhKxePbf+jkS4REZFUptCVZGqbh1+5WAM5xZBfkbiiREREZMwUupJIV18/TUf7hq1EH26iH1iz\nS0RERFKSQlcSOW7PxYAPWnZralFERGQcUOhKIrXh0FVVFt7U2rMLQgE10YuIiIwDCl1JpM7jJdOV\nxozC8JWLaqIXEREZNxS6kkitx8vcklzSXeE/lsYayCqAKbMTWpeIiIiMnUJXEnF7vMwbvhJ9+XJI\n0x+TiIhIqtNv8yTR1x/kYHvP4HIRwQA079TUooiIyDih0JUk6lq8WAtVpeEm+tZaCPSqiV5ERGSc\nUOhKEsdtdK0mehERkXFFoStJ1DZ7caUZZhfnOAcaayA9G4qqEluYiIiIRIVCV5Jwe7zMmppDVrrL\nOdC4DcqWgis9sYWJiIhIVCh0JYlaT9fg1GIoBE01mloUEREZRxS6koA/EOJAa89g6OrYD76jaqIX\nEREZRxS6ksCB1m4CIUvVwEbXjTXOV410iYiIjBsKXUlg4MrFY8tFNG6DtHQoXZzAqkRERCSaFLqS\nwMBG13NLcp0DjdugZBGkZyWwKhEREYkmha4kUOvxMr1wEjmZ6WCtE7o0tSgiIjKuKHQlAbfHO9hE\n39UIPUfURC8iIjLOKHQlWDBkqWvxDu65qCZ6ERGRcUmhK8EOtffgD4SGbf9jnIVRRUREZNxQ6Eqw\n2uaBPRcjrlwsmg9ZeQmsSkRERKJNoSvB3C3DNrpuqlE/l4iIyDik0JVgtc1eSvOzmDwpA3raoPOg\n+rlERETGIYWuBHN7uiJWot/mfFXoEhERGXcUuhLIWussF1EyLHSVa3pRRERkvFHoSqDGzj66/UHm\nl0U00U+eCTlTE1uYiIiIRJ1CVwIN7Ll4bKRLTfQiIiLjlkJXAg3suVhVlge+Lmh1q59LRERknFLo\nSiC3x0thTgZFuZnQtMM5qNAlIiIyLil0JZDb08X80jyMMWqiFxERGecUuhLEWkutxzt0JfrcUsgv\nT2xhIiIiEhMKXQnS2u2no6f/+JXojUlsYSIiIhITCl0JMrDnYlVpHvT3gWe3+rlERETGsVGFLmPM\n5caYPcYYtzHmKyM8f6cxZrsxZqsx5lVjzOKI5/4m/Lo9xpj3R7P4VDZkz0XPLrBBhS4REZFx7JSh\nyxjjAh4APgAsBm6MDFVhj1prl1lrVwDfBe4Pv3YxcAOwBLgc+O/w+0147uYucjNdVEzOVhO9iIjI\nBDCaka7VgNtau9da6wfWAWsjT7DWHo14mAvY8P21wDprrc9auw9wh99vwnO3eJlflj945WLWZCic\nneiyREREJEZGE7oqgYMRjw+Fjw1hjPmsMaYOZ6Trc6fz2omottl7/Er0aqIXEREZt6LWSG+tfcBa\nOw/4MnDv6bzWGHOHMabaGFPd0tISrZKSVmdvP54un7MSfTAAzTvVzyUiIjLOjSZ0NQAzIh5PDx87\nkXXA1afzWmvtg9baVdbaVSUlJaMoKbUN2XPxyNsQ6FPoEhERGedGE7o2A1XGmDnGmEycxvj1kScY\nY6oiHl4J1IbvrwduMMZkGWPmAFXA62MvO7W5PV1AeM9FNdGLiIhMCOmnOsFaGzDG3AVsAFzAQ9ba\nncaY+4Bqa+164C5jzCVAP9AO3Bp+7U5jzGPALiAAfNZaG4zR95Iy3B4vWelpTC/Mgde3QfokKK46\n9QtFREQkZZ0ydAFYa58Fnh127KsR9+8+yWu/BXzrTAscj2o9XuaW5OFKM04TfflSSNNKGiIiIuOZ\nVqRPALfH66xEHwpBY436uURERCYAha446/EHONTe66xE374P/F0KXSIiIhOAQlec1Xm6gfCei2qi\nFxERmTAUuuLM3eJcuTh/IHSlZUDpogRXJSIiIrGm0BVntc1e0tMMs4pynSb60oWQnpXoskRERCTG\nFLrizO3xMrs4l0xXeM9F9XOJiIhMCApdceb2hPdcPHoYelqhYkWiSxIREZE4UOiKI18gyIG2Hq1E\nLyIiMgEpdMXR/iM9BEN2sIke4yyMKiIiIuOeQlcc1XoirlxsqnG2/snMTXBVIiIiEg8KXXHk9ngx\nBuaV5KmJXkREZIJR6IqjWo+XGYU5ZPvb4WiDQpeIiMgEotAVR3UDey6qiV5ERGTCUeiKk0AwxN6W\n7ogmeqBCoUtERGSiUOiKk4PtvfiDocEm+ikzYVJhossSERGROFHoipPa5mF7LqqfS0REZEJR6IqT\nWo8XgPmTLbTtVegSERGZYBS64qTO46W8IJv89t3OgXKFLhERkYlEoStOaj3eodv/aKRLRERkQlHo\nioNQyFLX4h1sos8rg/yyRJclIiIicaTQFQeHO3vp8QfVRC8iIjKBKXTFgTvcRL9gaga07FHoEhER\nmYAUuuLgWOgy9WCDWoleRERkAlLoioPaZi9FuZlMbt/pHNBIl4iIyISj0BUH7hYv8waa6LOnOKvR\ni4iIyISi0BVj1lpqm7sGN7quWA7GJLosERERiTOFrhhr8fo42hdgQXEWNO/S1KKIiMgEpdAVY+5m\np4l+WZYHgj6tRC8iIjJBKXTFmLvFCV3zgm7ngEa6REREJiSFrhirbfaSn5VOQfsuyMiBonmJLklE\nREQSQKErxtweL/PL8jBNNVC+DNJciS5JREREEkChK8ZqPV6qinOgabumFkVERCYwha4Y6ujxc8Tr\n49yCdvB7tRK9iIjIBKbQFUMD2/8sNfudAxrpEhERmbAUumKoNhy6ZvjdkJYBJQsTXJGIiIgkikJX\nDLk9XrIz0shv2wlliyE9M9EliYiISIIodMVQrcfLvOJc58pFTS2KiIhMaApdMVTn8XLe1B7obVMT\nvYiIyASn0BUjXl+Aho5ezss66ByoWJHYgkRERCShFLpipC7cRH+W3QcmDcqWJLgiERERSSSFrhgZ\nWC6ioncPFC+AzJwEVyQiIiKJpNAVI7UeLxkuQ07rLjXRi4iIiEJXrLg9XlZO9WO6DquJXkRERBS6\nYsXt6eI9+Y3OA410iYiITHgKXTHQ1x+kvq2HszPqnQPlyxJbkIiIiCScQlcM7DvSTcjCvP46KJwN\nk6YkuiQRERFJMIWuGBjYc7HY+5amFkVERARQ6IoJt8fLZNND5tEDaqIXERERQKErJtyeLi6c3OQ8\n0Er0IiIigkJXTLg9Xi7IaXAeVGikS0RERBS6oi4QDLHvSDdLzD7Ir4C80kSXJCIiIklAoSvKDrT1\n0B+0zPC71UQvIiIixyh0RVlts5dsfBR496qJXkRERI5R6Ioyt6eLheYgxoY00iUiIiLHKHRFmdvj\n5Z25aqIXERGRoRS6oqzW4+W8rHqYVAiTZyS6HBEREUkSowpdxpjLjTF7jDFuY8xXRnj+HmPMLmNM\njTHmD8aYWRHPBY0xW8O39dEsPtmEQpa6Fi8L7D5natGYRJckIiIiSSL9VCcYY1zAA8ClwCFgszFm\nvbV2V8RpW4BV1toeY8xfAt8FPhp+rtdaOyFWCG3o6CXQ76esrw7KL0t0OSIiIpJERjPStRpwW2v3\nWmv9wDpgbeQJ1to/Wmt7wg83AtOjW2ZqcHu8VJkGXKF+NdGLiIjIEKMJXZXAwYjHh8LHTuQ24LmI\nx9nGmGpjzEZjzNUjvcAYc0f4nOqWlpZRlJScaj1dLE3b5zxQ6BIREZEIp5xePB3GmFuAVcB7Iw7P\nstY2GGPmAi8aY7Zba+siX2etfRB4EGDVqlU2mjXFU22zl1WZByEjD6bOS3Q5IiIikkRGM9LVAERe\nhjc9fGwIY8wlwN8BV1lrfQPHrbUN4a97gZeAlWOoN6m5W7ycnVEP5csgTReGioiIyKDRJIPNQJUx\nZo4xJhO4ARhyFaIxZiXwA5zA5Yk4XmiMyQrfLwbeCUQ24I8b1lr2Nh9lTkAr0YuIiMjxTjm9aK0N\nGGPuAjYALuAha+1OY8x9QLW1dj3wz0Ae8Lhxlkmot9ZeBSwCfmCMCeEEvG8Pu+px3PB0+SjyHyIr\nq1f9XCIiInKcUfV0WWufBZ4dduyrEfcvOcHrXgOWjaXAVFHb7GWp2e880Er0IiIiMowaj6LE7eli\nSdo+rCsTShYmuhwRERFJMgpdUVLr8XJ2ej2ULQFXRqLLERERkSSj0BUltc1dLDH7MGqiFxERkREo\ndEVJt2c/+darJnoREREZkUJXFLR1+5ne97bzQKFLRERERqDQFQVuj9dpojcup6dLREREZBiFriio\n9XSxxBwgMLUKMiYluhwRERFJQgpdUeD2eFmWtp/0Sk0tioiIyMiiuuH1RNXSWE+paYeKFYkuRURE\nRJKURrqiIMOzw7mjlehFRETkBBS6xqirr59pveErF8snxI5HIiIicgYUusbIuXJxP915syB7cqLL\nERERkSSl0DVGbo+XpWYfVivRi4iIyEkodI3RocOHmZnWwqSZKxNdioiIiCQxha4x6m+oAcA1TctF\niIiIyIkpdI1Rblv4ysVyhS4RERE5MYWuMejrD1LZV0tXZinklSS6HBEREUliCl1jUNfiZYnZT89U\n7bcoIiIiJ6fQNQb7DnuYaw7jqtRK9CIiInJyCl1jcPTAVlzGMnnuuYkuRURERJKcQtcYmEbnysWM\n6VouQkRERE5OoWsMJnfupittMhRUJroUERERSXIKXWfIHwgxy1fLkfyzwJhElyMiIiJJTqHrDB3w\ntFNlDtJfok2uRURE5NQUus6Qp24rmSZItrb/ERERkVFQ6DpDvfVvAlCyYHWCKxEREZFUoNB1hjJb\ndtDNJCaVViW6FBEREUkBCl1nqLjrLQ5lzYc0/ScUERGRU1NiOAPBQIDZgX10TlmU6FJEREQkRSh0\nnYGmfTvIMT5s+fJElyIiIiIpQqHrDLS7NwOQN3tVgisRERGRVKHQdQYCh7fRZzOYvkAbXYuIiMjo\nKHSdgdzWHdSlzWJy7qRElyIiIiIpQqHrdFlLRW8tTTkLEl2JiIiIpBCFrtNk2/eTZ730TF2S6FJE\nREQkhSh0naaOvdUAuKZr+x8REREZPYWu09S1700CNo2pcxS6REREZPQUuk6TadpGra1k/rSiRJci\nIiIiKUSh6zRN7nyL2rS5FOVmJroUERERSSEKXaejq4mCQCut+QsxxiS6GhEREUkhCl2nwR7eCoC/\nVNv/iIiIyOlR6DoNPfVbAJg0QyvRi4iIyOlJT3QBqcR38E2aQ+XMnlaW6FJEREQkxWik6zRktuxg\np53N/NK8RJciIiIiKUaha7R62sjrPUytmUvF5OxEVyMiIiIpRqFrtJpqAOgoXKwrF0VEROS0KXSN\nVqMTuijTlYsiIiJy+tRIP0r+Q1tosUVMq5ye6FJEREQkBWmka5SCh7exMzSb+SVqohcREZHTp9A1\nGj4v2Z172RmaTVWZQpeIiIicPoWu0WjegcHyVtpcphfmJLoaERERSUEKXaMRbqLvmboEV5quXBQR\nEZHTp9A1Go3baKeAwrJZia5EREREUpRC1yiEGrdRE5zN/LL8RJciIiIiKUqh61QCPoxnNzvtbKq0\n/Y+IiIicIYWuU/HswtgAO0Lac1FERETO3KhClzHmcmPMHmOM2xjzlRGev8cYs8sYU2OM+YMxZlbE\nc7caY2rDt1ujWXxchJvo9zCHWUW5CS5GREREUtUpQ5cxxgU8AHwAWAzcaIxZPOy0LcAqa+1y4Ang\nu+HXTgW+BqwBVgNfM8YURq/8OGjcRq/JxUydTWa6BgZFRETkzIwmRawG3NbavdZaP7AOWBt5grX2\nj9banvDDjcDAXjnvB5631rZZa9uB54HLo1N6nDTVsMfMYX7Z5ERXIiIiIilsNKGrEjgY8fhQ+NiJ\n3AY8dzqvNcbcYYypNsZUt7S0jKKkOAkFsU07eLN/hlaiFxERkTGJ6nyZMeYWYBXwz6fzOmvtg9ba\nVdbaVSUlJdEsaWyO1GICvWwPqoleRERExmY0oasBmBHxeHr42BDGmEuAvwOustb6Tue1SatxGwA7\nrUKXiIiIjM1oQtdmoMoYM8cYkwncAKyPPMEYsxL4AU7g8kQ8tQG4zBhTGG6gvyx8LDU0biOQlsVe\npjGvRKFLREREzlz6qU6w1gaMMXfhhCUX8JC1dqcx5j6g2lq7Hmc6MQ943BgDUG+tvcpa22aM+QZO\ncAO4z1rbFpPvJBaaajiYOZdp2flkZ7gSXY2IiIiksFOGLgBr7bPAs8OOfTXi/iUnee1DwENnWmDC\nWAuNNey0FzC/XKNcIiIiMjajCl0TUvt+8HWyMTBd2/+IiIjImGm1zxMJN9FvC85SE72IiIiMmULX\niTRuI2TSedtOV+gSERGRMVPoOpGmGtpy5uIjU6FLRERExkyhayTWQuM29qbPpbwgm/zsjERXJCIi\nIilOoWskXU3Q3cKWwCxt/yMiIiJRodA1knAT/StdWhRVREREokOhaySN27AYtvina6RLREREokKh\nayRNNfTmz6GbSVSV5ie6GhERERkHFLpG0riNxpwqAF25KCIiIlGh0DVcTxt0HmSPmUtRbiZTczMT\nXZGIiIiMAwpdw4Wb6Df3zWCeRrlEREQkShS6hguHrj90lGvPRREREYkaha7hmmoIFsygvi9b/Vwi\nIiISNQpdwzVuo2PyQgBduSgiIiJRo9AVydcFrXXUZzlXLmqNLhEREYkWha5ITTsAy47gbPKz0inN\nz0p0RSIiIjJOKHRFCjfR/7lnOvPL8jDGJLggERERGS8UuiI11UBuKa8fyWS+9lwUERGRKFLoitS4\njf7SpRzp9qufS0RERKJKoWtAfx+0vMWRfOfKRS0XISIiItGk0DXAswtCAepc8wAtFyEiIiLRpdA1\nINxEvyUwi+yMNCqnTEpwQSIiIjKepCe6gKTRVANZk9ncUcC8Ej9pabpyUURERKJHI10DGrdBxXLq\nWrq156KIiIhEnUIXQDAAzTvpL11GQ0evmuhFREQk6hS6AI68DYE+Gic52//MVxO9iIiIRJlCFxxr\non/LzAW0XISIiIhEn0IXOE306ZPY0lNChsswqygn0RWJiIjIOKPQBc5IV/lSalt6mVOcS4ZL/1lE\nREQkupQuQiFo2g4VZ+P2dGlqUURERGJCoat9H/iO0l+ylPq2HjXRi4iISEwodIWb6A9lLyBk1UQv\nIiIisaHQ1VQDaRnsClQCaGFUERERiQmFrsZtULqQPa1+0gzMKc5NdEUiIiIyDk3s0GUtNNYca6Kf\nOTWH7AxXoqsSERGRcej/t3d/MXaUdRjHv093bUtbhJKWBdoiWBqVCBVSESUhRjTBaCgXatBo0Gi8\nEQWjMeiFJl5xYQxeECNBlAQCIUhiY4hoEOOFSlqBAqVilwKlpWVbG2m3Wvrv58U5LUttwiI9Myed\n7yfZnDmzZ/c8zZvuPjvzvjPdLl27XoJ/74AzljM+MekkekmSNDDdLl39SfQHxi7guR17nEQvSZIG\npq6Au8AAAAdPSURBVNula9sTQNg0cyn7D5aT6CVJ0sB0u3RtXQsLlvGPnYcALxchSZIGp+OlqzeJ\n/tntkwAstXRJkqQB6W7p2rMDdm2GMy5kw8u7OeuU2cybNdp2KkmSdILqbunqT6LnzOVsmJjkvDFX\nLkqSpMHpbuna9gQAh8Yu5Nntk06ilyRJA9Xd0rV1LZx6NltencXe/YecRC9Jkgaqw6Xr8JXoe5Po\nPdIlSZIGqZula+8u2PksnLGcDRO7AS8XIUmSBqubpWvbk73H/pGuBfNmceqcme1mkiRJJ7SOlq7e\nJPojKxdPn9tuHkmSdMLrZunauhbmjVHzTmf85UmWeaNrSZI0YB0tXb1J9BO7X2X3qwdYNuZ8LkmS\nNFjdK10HD8C+3f0r0fdWLp630NIlSZIGq3v3vRkZhRuehEMHGf/LJgDO80iXJEkasO4d6Tpsxggb\nJiZ5++xRFs6b1XYaSZJ0gutu6QLGJyZZNnYySdqOIkmSTnCdL13O55IkSU2YVulKcmWSZ5KMJ7nx\nGJ+/PMmjSQ4k+dRRnzuY5PH+x6rjFfyt2rlnH//cs8+Vi5IkqRFvOJE+yQhwC/AxYDOwOsmqqnp6\nyss2AV8Evn2Mb/Gfqnrfcch6XB2+56K3/5EkSU2YzurFS4DxqtoIkOQeYCVwpHRV1fP9zx0aQMaB\n8J6LkiSpSdM5vbgIeHHK8839fdM1O8maJH9NcvWxXpDkq/3XrNm+ffub+Nb/v/GJSebMHOGsU05q\n5P0kSVK3NTGR/h1VtQL4HHBzkqVHv6Cqbq2qFVW1YuHChQ1E6pWupQvnMWOGKxclSdLgTad0bQGW\nTHm+uL9vWqpqS/9xI/BH4KI3kW9gxicmWeapRUmS1JDplK7VwLIk5yaZCVwDTGsVYpL5SWb1txcA\nlzFlLlhbdu/dz9ZX9rLU0iVJkhryhqWrqg4A1wEPAuuBe6tqXZIfJrkKIMn7k2wGPg38LMm6/pe/\nB1iTZC3wMHDTUaseW3F45aJHuiRJUlOmde/FqnoAeOCofd+fsr2a3mnHo7/uz8AFbzHjcXekdI2d\n3HISSZLUFZ28Iv34xCQzR2awZL4rFyVJUjM6W7reuXAuoyOd/OdLkqQWdLJ1bJiYdBK9JElqVOdK\n16FDxdmnzeHis+e3HUWSJHXItCbSn0hmzAh3fuUDbceQJEkd07kjXZIkSW2wdEmSJDXA0iVJktQA\nS5ckSVIDLF2SJEkNsHRJkiQ1wNIlSZLUAEuXJElSAyxdkiRJDbB0SZIkNcDSJUmS1ABLlyRJUgMs\nXZIkSQ2wdEmSJDXA0iVJktQAS5ckSVIDLF2SJEkNsHRJkiQ1IFXVdobXSbIdeKGBt1oA7GjgfTR9\njslwclyGj2MynByX4dPEmLyjqhZO54VDV7qakmRNVa1oO4de45gMJ8dl+Dgmw8lxGT7DNiaeXpQk\nSWqApUuSJKkBXS5dt7YdQP/DMRlOjsvwcUyGk+MyfIZqTDo7p0uSJKlJXT7SJUmS1BhLlyRJUgM6\nV7qSXJnkmSTjSW5sO48gyZIkDyd5Osm6JNe3nUk9SUaSPJbkN21nUU+SU5Pcl+TvSdYn+WDbmbou\nyTf7P7ueSnJ3ktltZ+qiJLcnmUjy1JR9pyX5fZIN/cf5bWbsVOlKMgLcAnwcOB/4bJLz200l4ADw\nrao6H7gU+JrjMjSuB9a3HUKv8xPgt1X1bmA5jk+rkiwCvgGsqKr3AiPANe2m6qxfAlcete9G4KGq\nWgY81H/emk6VLuASYLyqNlbVPuAeYGXLmTqvqrZW1aP97d30foksajeVkiwGPgHc1nYW9SQ5Bbgc\n+DlAVe2rqn+1m0rAKHBSklFgDvBSy3k6qar+BOw8avdK4I7+9h3A1Y2GOkrXStci4MUpzzfjL/eh\nkuQc4CLgkXaTCLgZ+A5wqO0gOuJcYDvwi/5p39uSzG07VJdV1RbgR8AmYCvwSlX9rt1UmmKsqrb2\nt7cBY22G6Vrp0hBLMg/4FXBDVe1qO0+XJfkkMFFVf2s7i15nFLgY+GlVXQTsoeXTJV3XnyO0kl4h\nPguYm+Tz7abSsVTvGlmtXiera6VrC7BkyvPF/X1qWZK30Stcd1XV/W3nEZcBVyV5nt5p+I8kubPd\nSKJ3dH5zVR0+EnwfvRKm9nwUeK6qtlfVfuB+4EMtZ9JrXk5yJkD/caLNMF0rXauBZUnOTTKT3mTH\nVS1n6rwkoTdHZX1V/bjtPIKq+m5VLa6qc+j9P/lDVfnXe8uqahvwYpJ39XddATzdYiT1TitemmRO\n/2fZFbi4YZisAq7tb18L/LrFLIy2+eZNq6oDSa4DHqS3wuT2qlrXciz1jqp8AXgyyeP9fd+rqgda\nzCQNq68Dd/X/cNwIfKnlPJ1WVY8kuQ94lN5K7McYslvPdEWSu4EPAwuSbAZ+ANwE3Jvky8ALwGfa\nS+htgCRJkhrRtdOLkiRJrbB0SZIkNcDSJUmS1ABLlyRJUgMsXZIkSQ2wdEmSJDXA0iVJktSA/wLC\nlrhwaPUtMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83190494a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N2 = len(solver.val_acc_history)\n",
    "x2 = range(N2)\n",
    "plt.plot(x2, solver.val_acc_history);\n",
    "plt.plot(x2, solver.train_acc_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer network\n",
    "Next you will implement a fully-connected network with an arbitrary number of hidden layers.\n",
    "\n",
    "Read through the `FullyConnectedNet` class in the file `cs231n/classifiers/fc_net.py`.\n",
    "\n",
    "Implement the initialization, the forward pass, and the backward pass. For the moment don't worry about implementing dropout or batch normalization; we will add those features soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial loss and gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, run the following to check the initial loss and to gradient check the network both with and without regularization. Do the initial losses seem reasonable?\n",
    "\n",
    "For gradient checking, you should expect to see errors around 1e-6 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another sanity check, make sure you can overfit a small dataset of 50 images. First we will try a three-layer network with 100 units in each hidden layer. You will need to tweak the learning rate and initialization scale, but you should be able to overfit and achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 1e-2\n",
    "learning_rate = 1e-4\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to use a five-layer network with 100 units on each layer to overfit 50 training examples. Again you will have to adjust the learning rate and weight initialization, but you should be able to achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_scale = 1e-5\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inline question: \n",
    "Did you notice anything about the comparative difficulty of training the three-layer net vs training the five layer net?\n",
    "\n",
    "# Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "So far we have used vanilla stochastic gradient descent (SGD) as our update rule. More sophisticated update rules can make it easier to train deep networks. We will implement a few of the most commonly used update rules and compare them to vanilla SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD+Momentum\n",
    "Stochastic gradient descent with momentum is a widely used update rule that tends to make deep networks converge faster than vanilla stochstic gradient descent.\n",
    "\n",
    "Open the file `cs231n/optim.py` and read the documentation at the top of the file to make sure you understand the API. Implement the SGD+momentum update rule in the function `sgd_momentum` and run the following to check your implementation. You should see errors less than 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cs231n.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have done so, run the following to train a six-layer network with both SGD and SGD+momentum. You should see the SGD+momentum update rule converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-2,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp and Adam\n",
    "RMSProp [1] and Adam [2] are update rules that set per-parameter learning rates by using a running average of the second moments of gradients.\n",
    "\n",
    "In the file `cs231n/optim.py`, implement the RMSProp update rule in the `rmsprop` function and implement the Adam update rule in the `adam` function, and check your implementations using the tests below.\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test RMSProp implementation; you should see errors less than 1e-7\n",
    "from cs231n.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test Adam implementation; you should see errors around 1e-7 or less\n",
    "from cs231n.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have debugged your RMSProp and Adam implementations, run the following to train a pair of deep networks using these new update rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': learning_rates[update_rule]\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a good model!\n",
    "Train the best fully-connected model that you can on CIFAR-10, storing your best model in the `best_model` variable. We require you to get at least 50% accuracy on the validation set using a fully-connected net.\n",
    "\n",
    "If you are careful it should be possible to get accuracies above 55%, but we don't require it for this part and won't assign extra credit for doing so. Later in the assignment we will ask you to train the best convolutional network that you can on CIFAR-10, and we would prefer that you spend your effort working on convolutional nets rather than fully-connected nets.\n",
    "\n",
    "You might find it useful to complete the `BatchNormalization.ipynb` and `Dropout.ipynb` notebooks before completing this part, since those techniques can help you train powerful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# batch normalization and dropout useful. Store your best model in the         #\n",
    "# best_model variable.                                                         #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test you model\n",
    "Run your best model on the validation and test sets. You should achieve above 50% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(data['X_val']), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
